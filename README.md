# ğŸ¬ ç”µå½±æ¨èç³»ç»Ÿ (Movie Recommendation System)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![LightGBM](https://img.shields.io/badge/LightGBM-Latest-green.svg)](https://lightgbm.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Production-brightgreen.svg)]()

ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„ç”µå½±è¯„åˆ†é¢„æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨åºæ•°åˆ†ç±»æ–¹æ³•é¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†ã€‚ç³»ç»Ÿé›†æˆäº†å¤šç§å…ˆè¿›çš„ç‰¹å¾å·¥ç¨‹æŠ€æœ¯å’Œå¯è§†åŒ–åˆ†æå·¥å…·ï¼Œæä¾›å®Œæ•´çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#-é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [æŠ€æœ¯æ¶æ„](#-æŠ€æœ¯æ¶æ„)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [å®‰è£…æŒ‡å—](#-å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨è¯´æ˜](#-è¯¦ç»†ä½¿ç”¨è¯´æ˜)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [APIæ–‡æ¡£](#-apiæ–‡æ¡£)
- [å®éªŒç®¡ç†](#-å®éªŒç®¡ç†)
- [æ€§èƒ½è¯„ä¼°](#-æ€§èƒ½è¯„ä¼°)
- [å¯è§†åŒ–åˆ†æ](#-å¯è§†åŒ–åˆ†æ)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)
- [æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)
- [è®¸å¯è¯](#-è®¸å¯è¯)

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªä¸“ä¸šçº§çš„ç”µå½±æ¨èç³»ç»Ÿï¼Œä¸“æ³¨äºé¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†ã€‚ç³»ç»Ÿé‡‡ç”¨åºæ•°åˆ†ç±»ï¼ˆOrdinal Classificationï¼‰æ–¹æ³•ï¼Œå°†è¯„åˆ†é¢„æµ‹é—®é¢˜è½¬æ¢ä¸ºå¤šä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è¯„åˆ†æ•°æ®çš„æœ‰åºæ€§ç‰¹å¾ã€‚

### ğŸª ä¸»è¦åº”ç”¨åœºæ™¯

- **ç”µå½±æ¨èå¹³å°**: ä¸ºç”¨æˆ·æ¨èå¯èƒ½å–œæ¬¢çš„ç”µå½±
- **å†…å®¹åˆ†æ**: åˆ†æç”µå½±è´¨é‡å’Œç”¨æˆ·åå¥½è¶‹åŠ¿
- **ä¸ªæ€§åŒ–æœåŠ¡**: åŸºäºç”¨æˆ·å†å²è¡Œä¸ºæä¾›ä¸ªæ€§åŒ–æ¨è
- **å¸‚åœºç ”ç©¶**: ç”µå½±å¸‚åœºåˆ†æå’Œé¢„æµ‹
- **å­¦æœ¯ç ”ç©¶**: æ¨èç®—æ³•å’Œæœºå™¨å­¦ä¹ ç ”ç©¶

### ğŸ† é¡¹ç›®äº®ç‚¹

- **å…ˆè¿›ç®—æ³•**: åŸºäºLightGBMçš„åºæ•°åˆ†ç±»ï¼Œå¤„ç†è¯„åˆ†çš„æœ‰åºæ€§
- **å¤šç»´ç‰¹å¾**: é›†æˆååŒè¿‡æ»¤ã€å†…å®¹ç‰¹å¾ã€æ–‡æœ¬ç‰¹å¾ç­‰å¤šç§ç‰¹å¾å·¥ç¨‹
- **æ•°æ®è´¨é‡**: å†…ç½®å¼‚å¸¸å€¼æ£€æµ‹å’Œæ•°æ®è´¨é‡æ§åˆ¶
- **å¯è§†åŒ–ä¸°å¯Œ**: æä¾›20+ç§ä¸“ä¸šç»Ÿè®¡å›¾è¡¨å’Œåˆ†æå·¥å…·
- **å®éªŒç®¡ç†**: å®Œæ•´çš„å®éªŒè®°å½•å’Œç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
- **ç”Ÿäº§å°±ç»ª**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºéƒ¨ç½²å’Œæ‰©å±•

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ”§ ç‰¹å¾å·¥ç¨‹

- **ååŒè¿‡æ»¤ç‰¹å¾**: åŸºäºSVDçŸ©é˜µåˆ†è§£çš„ç”¨æˆ·-ç‰©å“éšå› å­
- **å†…å®¹ç‰¹å¾**: ç”µå½±ç±»å‹ã€å¹´ä»½ã€å¯¼æ¼”ç­‰ç»“æ„åŒ–ä¿¡æ¯
- **æ–‡æœ¬ç‰¹å¾**: åŸºäºTF-IDFçš„ç”¨æˆ·æ ‡ç­¾å’Œè¯„è®ºç‰¹å¾
- **ç”¨æˆ·ç”»åƒ**: ç”¨æˆ·è¯„åˆ†è¡Œä¸ºã€åå¥½æ¨¡å¼ã€æ´»è·ƒåº¦ç‰¹å¾
- **ç”µå½±ç”»åƒ**: ç”µå½±è´¨é‡ã€çƒ­åº¦ã€ç±»å‹åˆ†å¸ƒç‰¹å¾
- **äº¤å‰ç‰¹å¾**: ç”¨æˆ·-ç‰©å“äº¤äº’ç‰¹å¾å’Œæ—¶é—´ç‰¹å¾

### ğŸ¤– æ¨¡å‹ç®—æ³•

- **åºæ•°åˆ†ç±»**: CORALé£æ ¼çš„å¤šäºŒåˆ†ç±»å™¨æ¶æ„
- **LightGBM**: é«˜æ•ˆçš„æ¢¯åº¦æå‡å†³ç­–æ ‘
- **ç‰¹å¾é€‰æ‹©**: è‡ªåŠ¨ç‰¹å¾é‡è¦æ€§åˆ†æå’Œé€‰æ‹©
- **è¶…å‚æ•°ä¼˜åŒ–**: æ”¯æŒç½‘æ ¼æœç´¢å’Œè´å¶æ–¯ä¼˜åŒ–
- **æ¨¡å‹é›†æˆ**: æ”¯æŒå¤šæ¨¡å‹èåˆå’ŒæŠ•ç¥¨æœºåˆ¶

### ğŸ“Š è¯„ä¼°ä½“ç³»

- **å›å½’æŒ‡æ ‡**: RMSE, MAE, RÂ²ç­‰
- **åˆ†ç±»æŒ‡æ ‡**: å‡†ç¡®ç‡, ç²¾ç¡®ç‡, å¬å›ç‡, F1-Score
- **æ’åºæŒ‡æ ‡**: NDCG, MAP, MRR
- **åˆ†å±‚åˆ†æ**: æŒ‰ç”¨æˆ·ç¾¤ä½“ã€ç”µå½±ç±»å‹ã€æ—¶é—´æ®µçš„æ€§èƒ½åˆ†æ
- **è¯¯å·®åˆ†æ**: é¢„æµ‹åå·®æ¨¡å¼å’Œå¼‚å¸¸å€¼åˆ†æ

### ğŸ¨ å¯è§†åŒ–åˆ†æ

- **é¢„æµ‹æ•ˆæœ**: çœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾ã€ç®±çº¿å›¾
- **è¯¯å·®åˆ†æ**: è¯¯å·®åˆ†å¸ƒã€æ··æ·†çŸ©é˜µã€ç”¨æˆ·è¯¯å·®åˆ†å¸ƒ
- **ç‰¹å¾åˆ†æ**: ç‰¹å¾é‡è¦æ€§ã€ç›¸å…³æ€§çƒ­åŠ›å›¾ã€åˆ†å¸ƒå›¾
- **æ—¶é—´åˆ†æ**: è¯„åˆ†è¶‹åŠ¿ã€å­£èŠ‚æ€§æ¨¡å¼åˆ†æ
- **ç”¨æˆ·åˆ†æ**: ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ã€åå¥½åˆ†æ

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”µå½±æ¨èç³»ç»Ÿæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å±‚ (Data Layer)                                        â”‚
â”‚  â”œâ”€â”€ MovieLensæ•°æ®é›† (ratings.csv, movies.csv, tags.csv)    â”‚
â”‚  â”œâ”€â”€ æ•°æ®é¢„å¤„ç† (å¼‚å¸¸å€¼æ£€æµ‹, æ•°æ®æ¸…æ´—)                        â”‚
â”‚  â””â”€â”€ æ•°æ®è´¨é‡æ§åˆ¶ (å®Œæ•´æ€§æ£€æŸ¥, æ ¼å¼éªŒè¯)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç‰¹å¾å±‚ (Feature Layer)                                     â”‚
â”‚  â”œâ”€â”€ ååŒè¿‡æ»¤ç‰¹å¾ (SVDçŸ©é˜µåˆ†è§£)                              â”‚
â”‚  â”œâ”€â”€ å†…å®¹ç‰¹å¾ (ç”µå½±ç±»å‹, å¹´ä»½)                               â”‚
â”‚  â”œâ”€â”€ æ–‡æœ¬ç‰¹å¾ (TF-IDFæ ‡ç­¾ç‰¹å¾)                               â”‚
â”‚  â”œâ”€â”€ ç”¨æˆ·ç”»åƒ (è¯„åˆ†è¡Œä¸º, åå¥½æ¨¡å¼)                           â”‚
â”‚  â”œâ”€â”€ ç”µå½±ç”»åƒ (è´¨é‡æŒ‡æ ‡, çƒ­åº¦ç‰¹å¾)                           â”‚
â”‚  â””â”€â”€ äº¤å‰ç‰¹å¾ (ç”¨æˆ·-ç‰©å“äº¤äº’)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¨¡å‹å±‚ (Model Layer)                                       â”‚
â”‚  â”œâ”€â”€ åºæ•°åˆ†ç±»å™¨ (å¤šä¸ªLightGBMäºŒåˆ†ç±»å™¨)                       â”‚
â”‚  â”œâ”€â”€ ç‰¹å¾é€‰æ‹© (é‡è¦æ€§åˆ†æ)                                   â”‚
â”‚  â”œâ”€â”€ è¶…å‚æ•°ä¼˜åŒ– (ç½‘æ ¼æœç´¢)                                   â”‚
â”‚  â””â”€â”€ æ¨¡å‹é›†æˆ (æŠ•ç¥¨æœºåˆ¶)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¯„ä¼°å±‚ (Evaluation Layer)                                  â”‚
â”‚  â”œâ”€â”€ å¤šæŒ‡æ ‡è¯„ä¼° (RMSE, MAE, å‡†ç¡®ç‡ç­‰)                        â”‚
â”‚  â”œâ”€â”€ åˆ†å±‚åˆ†æ (ç”¨æˆ·ç¾¤ä½“, ç”µå½±ç±»å‹)                           â”‚
â”‚  â”œâ”€â”€ è¯¯å·®åˆ†æ (é¢„æµ‹åå·®, å¼‚å¸¸æ£€æµ‹)                           â”‚
â”‚  â””â”€â”€ æ€§èƒ½ç›‘æ§ (è®­ç»ƒæ›²çº¿, éªŒè¯æ›²çº¿)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¯è§†åŒ–å±‚ (Visualization Layer)                             â”‚
â”‚  â”œâ”€â”€ é¢„æµ‹æ•ˆæœå›¾è¡¨ (æ•£ç‚¹å›¾, ç®±çº¿å›¾)                           â”‚
â”‚  â”œâ”€â”€ è¯¯å·®åˆ†æå›¾è¡¨ (åˆ†å¸ƒå›¾, çƒ­åŠ›å›¾)                           â”‚
â”‚  â”œâ”€â”€ ç‰¹å¾åˆ†æå›¾è¡¨ (é‡è¦æ€§, ç›¸å…³æ€§)                           â”‚
â”‚  â””â”€â”€ æ—¶é—´åºåˆ—å›¾è¡¨ (è¶‹åŠ¿åˆ†æ)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨å±‚ (Application Layer)                                 â”‚
â”‚  â”œâ”€â”€ å®éªŒç®¡ç† (ç‰ˆæœ¬æ§åˆ¶, ç»“æœè¿½è¸ª)                           â”‚
â”‚  â”œâ”€â”€ é…ç½®ç®¡ç† (å‚æ•°è®¾ç½®, ç¯å¢ƒé…ç½®)                           â”‚
â”‚  â”œâ”€â”€ æ—¥å¿—ç³»ç»Ÿ (è¿è¡Œæ—¥å¿—, é”™è¯¯è¿½è¸ª)                           â”‚
â”‚  â””â”€â”€ APIæ¥å£ (é¢„æµ‹æœåŠ¡, æ¨¡å‹ç®¡ç†)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
2025_ML_Code/
â”œâ”€â”€ ğŸ“„ README.md                    # é¡¹ç›®æ–‡æ¡£ (æœ¬æ–‡ä»¶)
â”œâ”€â”€ ğŸ“„ requirements.txt             # Pythonä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ ğŸ“„ setup.py                     # é¡¹ç›®å®‰è£…é…ç½®
â”œâ”€â”€ ğŸ“„ .gitignore                   # Gitå¿½ç•¥æ–‡ä»¶é…ç½®
â”œâ”€â”€ ğŸ“„ LICENSE                      # å¼€æºè®¸å¯è¯
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ config.py                    # ğŸ”§ å…¨å±€é…ç½®ç®¡ç†
â”œâ”€â”€ ğŸ—‚ï¸ main.py                      # ğŸš€ ä¸»ç¨‹åºå…¥å£
â”‚
â”œâ”€â”€ ğŸ“ data/                        # ğŸ“Š æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py           # æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹
â”‚   â””â”€â”€ ğŸ“„ data_preprocessing.py    # æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—
â”‚
â”œâ”€â”€ ğŸ“ models/                      # ğŸ¤– æ¨¡å‹ç›¸å…³æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ train_eval.py            # æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
â”‚   â””â”€â”€ ğŸ“„ model_utils.py           # æ¨¡å‹å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ ğŸ“ utils/                       # ğŸ› ï¸ å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ logger.py                # æ—¥å¿—è®°å½•å·¥å…·
â”‚   â””â”€â”€ ğŸ“„ metrics.py               # è¯„ä¼°æŒ‡æ ‡å‡½æ•°
â”‚
â”œâ”€â”€ ğŸ“ visualization/               # ğŸ“ˆ å¯è§†åŒ–æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ basic_plots.py           # åŸºç¡€å›¾è¡¨
â”‚   â”œâ”€â”€ ğŸ“„ error_analysis.py        # è¯¯å·®åˆ†æå›¾è¡¨
â”‚   â””â”€â”€ ğŸ“„ feature_plots.py         # ç‰¹å¾åˆ†æå›¾è¡¨
â”‚
â”œâ”€â”€ ğŸ“ experiments/                 # ğŸ§ª å®éªŒç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ experiment.py            # å®éªŒç®¡ç†ç±»
â”‚   â””â”€â”€ ğŸ“ [å®éªŒè®°å½•ç›®å½•]/           # å„æ¬¡å®éªŒçš„ç»“æœ
â”‚       â”œâ”€â”€ ğŸ“„ config.json          # å®éªŒé…ç½®
â”‚       â”œâ”€â”€ ğŸ“„ results.json         # å®éªŒç»“æœ
â”‚       â”œâ”€â”€ ğŸ“„ predictions.csv      # é¢„æµ‹ç»“æœ
â”‚       â”œâ”€â”€ ğŸ“ plots/               # å¯è§†åŒ–å›¾è¡¨
â”‚       â”œâ”€â”€ ğŸ“ models/              # è®­ç»ƒæ¨¡å‹
â”‚       â””â”€â”€ ğŸ“ logs/                # å®éªŒæ—¥å¿—
â”‚
â”œâ”€â”€ ğŸ“ output/                      # ğŸ“¤ è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ ğŸ“„ predictions.csv          # æœ€æ–°é¢„æµ‹ç»“æœ
â”‚   â””â”€â”€ ğŸ“„ *.png                    # ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
â”‚
â”œâ”€â”€ ğŸ“ logs/                        # ğŸ“ æ—¥å¿—ç›®å½•
â”‚   â””â”€â”€ ğŸ“„ *.log                    # è¿è¡Œæ—¥å¿—æ–‡ä»¶
â”‚
â”œâ”€â”€ ğŸ“ tests/                       # ğŸ§ª æµ‹è¯•æ¨¡å—
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py              # æµ‹è¯•åˆå§‹åŒ–
â”‚   â”œâ”€â”€ ğŸ“„ test_data_loader.py      # æ•°æ®åŠ è½½æµ‹è¯•
â”‚   â”œâ”€â”€ ğŸ“„ test_models.py           # æ¨¡å‹æµ‹è¯•
â”‚   â””â”€â”€ ğŸ“„ test_utils.py            # å·¥å…·å‡½æ•°æµ‹è¯•
â”‚
â”œâ”€â”€ ğŸ“ docs/                        # ğŸ“š æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ ğŸ“„ API.md                   # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ ğŸ“„ TUTORIAL.md              # ä½¿ç”¨æ•™ç¨‹
â”‚   â”œâ”€â”€ ğŸ“„ ALGORITHM.md             # ç®—æ³•è¯´æ˜
â”‚   â””â”€â”€ ğŸ“„ DEPLOYMENT.md            # éƒ¨ç½²æŒ‡å—
â”‚
â””â”€â”€ ğŸ“ scripts/                     # ğŸ“œ è„šæœ¬ç›®å½•
    â”œâ”€â”€ ğŸ“„ download_data.py         # æ•°æ®ä¸‹è½½è„šæœ¬
    â”œâ”€â”€ ğŸ“„ preprocess_data.py       # æ•°æ®é¢„å¤„ç†è„šæœ¬
    â””â”€â”€ ğŸ“„ run_experiments.py       # æ‰¹é‡å®éªŒè„šæœ¬
```

### ğŸ“‹ æ ¸å¿ƒæ¨¡å—è¯´æ˜

| æ¨¡å— | åŠŸèƒ½æè¿° | ä¸»è¦æ–‡ä»¶ |
|------|----------|----------|
| **config** | å…¨å±€é…ç½®ç®¡ç†ï¼ŒåŒ…å«æ‰€æœ‰ç³»ç»Ÿå‚æ•° | `config.py` |
| **data** | æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ | `data_loader.py`, `data_preprocessing.py` |
| **models** | æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼° | `train_eval.py`, `model_utils.py` |
| **utils** | å·¥å…·å‡½æ•°ã€æ—¥å¿—ã€è¯„ä¼°æŒ‡æ ‡ | `logger.py`, `metrics.py` |
| **visualization** | å¯è§†åŒ–åˆ†æå’Œå›¾è¡¨ç”Ÿæˆ | `basic_plots.py`, `error_analysis.py`, `feature_plots.py` |
| **experiments** | å®éªŒç®¡ç†ã€ç‰ˆæœ¬æ§åˆ¶ã€ç»“æœè¿½è¸ª | `experiment.py` |

## ğŸš€ å®‰è£…æŒ‡å—

### ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+ (æ¨è 3.9+)
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.14+, Ubuntu 18.04+
- **å†…å­˜**: æœ€ä½ 4GB RAM (æ¨è 8GB+)
- **å­˜å‚¨**: æœ€ä½ 2GB å¯ç”¨ç©ºé—´
- **CPU**: æ”¯æŒå¤šæ ¸å¤„ç†å™¨ (æ¨è 4æ ¸+)

### ğŸ“¦ ä¾èµ–åŒ…

#### æ ¸å¿ƒä¾èµ–
```
pandas>=1.3.0          # æ•°æ®å¤„ç†
numpy>=1.21.0           # æ•°å€¼è®¡ç®—
scikit-learn>=1.0.0     # æœºå™¨å­¦ä¹ å·¥å…·
lightgbm>=3.3.0         # æ¢¯åº¦æå‡æ¨¡å‹
scikit-surprise>=1.1.1  # æ¨èç³»ç»Ÿç®—æ³•
```

#### å¯è§†åŒ–ä¾èµ–
```
matplotlib>=3.5.0       # åŸºç¡€ç»˜å›¾
seaborn>=0.11.0         # ç»Ÿè®¡å›¾è¡¨
plotly>=5.0.0           # äº¤äº’å¼å›¾è¡¨
```

#### å·¥å…·ä¾èµ–
```
tqdm>=4.62.0            # è¿›åº¦æ¡
loguru>=0.6.0           # æ—¥å¿—ç®¡ç†
jupyter>=1.0.0          # äº¤äº’å¼å¼€å‘
```

### ğŸ”§ å®‰è£…æ­¥éª¤

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ pip å®‰è£… (æ¨è)

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
python -m venv movie_rec_env

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows:
movie_rec_env\Scripts\activate
# macOS/Linux:
source movie_rec_env/bin/activate

# 4. å‡çº§ pip
pip install --upgrade pip

# 5. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 6. éªŒè¯å®‰è£…
python -c "import lightgbm, pandas, sklearn; print('å®‰è£…æˆåŠŸ!')"
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨ conda å®‰è£…

```bash
# 1. åˆ›å»º conda ç¯å¢ƒ
conda create -n movie_rec python=3.9
conda activate movie_rec

# 2. å®‰è£…ä¾èµ–
conda install pandas numpy scikit-learn matplotlib seaborn
pip install lightgbm scikit-surprise tqdm loguru

# 3. å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system
```

#### æ–¹æ³•ä¸‰ï¼šDocker å®‰è£…

```bash
# 1. æ„å»º Docker é•œåƒ
docker build -t movie-rec-system .

# 2. è¿è¡Œå®¹å™¨
docker run -it --rm -v $(pwd):/app movie-rec-system
```

### ğŸ“Š æ•°æ®å‡†å¤‡

#### ä¸‹è½½ MovieLens æ•°æ®é›†

```bash
# è‡ªåŠ¨ä¸‹è½½è„šæœ¬
python scripts/download_data.py

# æˆ–æ‰‹åŠ¨ä¸‹è½½
# 1. è®¿é—® https://grouplens.org/datasets/movielens/
# 2. ä¸‹è½½ ml-latest-small.zip
# 3. è§£å‹åˆ°é¡¹ç›®æ ¹ç›®å½•
```

#### æ•°æ®é›†ç»“æ„
```
ml-latest-small/
â”œâ”€â”€ ratings.csv         # ç”¨æˆ·è¯„åˆ†æ•°æ®
â”œâ”€â”€ movies.csv          # ç”µå½±ä¿¡æ¯æ•°æ®
â”œâ”€â”€ tags.csv            # ç”¨æˆ·æ ‡ç­¾æ•°æ®
â””â”€â”€ links.csv           # ç”µå½±é“¾æ¥æ•°æ® (å¯é€‰)
```

### âœ… å®‰è£…éªŒè¯

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python -m pytest tests/ -v

# æˆ–è¿è¡Œå¿«é€Ÿæµ‹è¯•
python scripts/test_installation.py
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ¯ 5åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

```bash
# 1. ç¡®ä¿æ•°æ®å·²å‡†å¤‡å¥½
ls ml-latest-small/  # åº”è¯¥çœ‹åˆ° ratings.csv, movies.csv, tags.csv

# 2. è¿è¡Œä¸»ç¨‹åº
python main.py

# 3. æŸ¥çœ‹ç»“æœ
ls output/  # æŸ¥çœ‹ç”Ÿæˆçš„é¢„æµ‹ç»“æœå’Œå›¾è¡¨
```

### ğŸ“Š æŸ¥çœ‹ç»“æœ

è¿è¡Œå®Œæˆåï¼Œæ‚¨å°†åœ¨ `output/` ç›®å½•ä¸‹çœ‹åˆ°ï¼š

- **predictions.csv**: é¢„æµ‹ç»“æœæ–‡ä»¶
- **å„ç§ .png å›¾è¡¨**: å¯è§†åŒ–åˆ†æç»“æœ
- **å®éªŒè®°å½•**: åœ¨ `experiments/` ç›®å½•ä¸‹

### ğŸ¨ å¯è§†åŒ–ç»“æœé¢„è§ˆ

ç¨‹åºä¼šè‡ªåŠ¨ç”Ÿæˆä»¥ä¸‹å›¾è¡¨ï¼š

1. **é¢„æµ‹æ•ˆæœå›¾è¡¨**
   - `boxplot_true_vs_pred.png`: çœŸå®å€¼vsé¢„æµ‹å€¼ç®±çº¿å›¾
   - `predicted_rating_hist.png`: é¢„æµ‹è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾

2. **è¯¯å·®åˆ†æå›¾è¡¨**
   - `prediction_error_hist.png`: é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
   - `mean_error_per_rating.png`: å„è¯„åˆ†ç­‰çº§çš„å¹³å‡è¯¯å·®
   - `confusion_heatmap.png`: é¢„æµ‹æ··æ·†çŸ©é˜µ

3. **ç‰¹å¾åˆ†æå›¾è¡¨**
   - `top20_feature_importance.png`: Top20ç‰¹å¾é‡è¦æ€§
   - `feature_correlation_heatmap.png`: ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾

## ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜

### ğŸ”§ é…ç½®ç³»ç»Ÿ

ç³»ç»Ÿé‡‡ç”¨é›†ä¸­å¼é…ç½®ç®¡ç†ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨ `config.py` ä¸­å®šä¹‰ï¼š

```python
from config import config

# æŸ¥çœ‹å½“å‰é…ç½®
print(f"æ¨¡å‹åç§°: {config.model_name}")
print(f"æ•°æ®è·¯å¾„: {config.base_dir}")
print(f"éšå› å­ç»´åº¦: {config.latent_dim}")

# ä¿®æ”¹é…ç½® (ä¸æ¨èç›´æ¥ä¿®æ”¹ï¼Œå»ºè®®åˆ›å»ºæ–°çš„é…ç½®ç±»)
config.n_estimators = 500
config.learning_rate = 0.1
```

### ğŸ“Š æ•°æ®å¤„ç†æµç¨‹

#### 1. æ•°æ®åŠ è½½

```python
from data.data_loader import load_data

# åŠ è½½æ•°æ® (åŒ…å«é¢„å¤„ç†)
ratings, movies, tags, report = load_data(
    enable_preprocessing=True,
    outlier_strategy='flag'
)

print(f"è¯„åˆ†è®°å½•æ•°: {len(ratings)}")
print(f"ç”µå½±æ•°é‡: {len(movies)}")
print(f"æ•°æ®è´¨é‡è¯„åˆ†: {report['quality_score']}")
```

#### 2. ç‰¹å¾å·¥ç¨‹

```python
from data.data_loader import (
    create_collaborative_filtering_features,
    create_content_features,
    create_tfidf_tag_features,
    create_user_profile_features,
    create_movie_profile_features
)

# ååŒè¿‡æ»¤ç‰¹å¾
user_f, item_f, user_bias, item_bias = create_collaborative_filtering_features(ratings)

# å†…å®¹ç‰¹å¾
movies_feats, mlb = create_content_features(movies)

# TF-IDFç‰¹å¾
rat_tag, tag_df = create_tfidf_tag_features(ratings, tags)

# ç”¨æˆ·ç”»åƒ
user_stats, user_genre_pref = create_user_profile_features(ratings, movies)

# ç”µå½±ç”»åƒ
movie_stats = create_movie_profile_features(ratings)
```

### ğŸ¤– æ¨¡å‹è®­ç»ƒ

#### 1. åŸºç¡€è®­ç»ƒ

```python
from models.train_eval import train_models, predict
from models.model_utils import rating_to_label, label_to_rating

# å‡†å¤‡æ•°æ®
X_train = df[feature_columns].values
y_train = df['rating'].apply(rating_to_label).values

# è®­ç»ƒæ¨¡å‹
models = train_models(
    X_train, y_train,
    num_classes=10,
    n_estimators=1000,
    learning_rate=0.05
)

# é¢„æµ‹
pred_labels = predict(models, X_val)
pred_ratings = [label_to_rating(label) for label in pred_labels]
```

#### 2. é«˜çº§è®­ç»ƒé€‰é¡¹

```python
# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
models = train_models(
    X_train, y_train,
    num_classes=10,
    n_estimators=1000,
    learning_rate=0.05,
    num_leaves=63,
    categorical_features=['year_r', 'month_r'],
    verbose=True
)

# è·å–ç‰¹å¾é‡è¦æ€§
feature_importance = models[0].feature_importances_
top_features = sorted(zip(feature_names, feature_importance), 
                     key=lambda x: x[1], reverse=True)[:20]
```

### ğŸ“ˆ è¯„ä¼°å’Œå¯è§†åŒ–

#### 1. æ€§èƒ½è¯„ä¼°

```python
from utils.metrics import compute_rmse, rmse_by_class
from models.train_eval import evaluate_models

# åŸºç¡€æŒ‡æ ‡
rmse = compute_rmse(true_ratings, pred_ratings)
print(f"RMSE: {rmse:.4f}")

# åˆ†ç±»è¯„ä¼°
class_rmse = rmse_by_class(true_ratings, pred_ratings)
print(f"å„ç±»åˆ«RMSE: {class_rmse}")

# è¯¦ç»†è¯„ä¼°
eval_results = evaluate_models(models, X_val, y_val)
print(f"å‡†ç¡®ç‡: {eval_results['accuracy']:.4f}")
```

#### 2. å¯è§†åŒ–åˆ†æ

```python
from visualization.error_analysis import (
    plot_error_distribution,
    plot_confusion_heatmap,
    plot_user_error_distribution
)
from visualization.feature_plots import (
    plot_top20_feature_importance,
    plot_feature_correlation
)

# è¯¯å·®åˆ†æ
plot_error_distribution(predictions_df)
plot_confusion_heatmap(predictions_df)

# ç‰¹å¾åˆ†æ
plot_top20_feature_importance(models, X_train)
plot_feature_correlation(df, feature_columns, 'rating')
```

### ğŸ§ª å®éªŒç®¡ç†

#### 1. åˆ›å»ºå®éªŒ

```python
from experiments.experiment import Experiment

# åˆ›å»ºå®éªŒ
exp = Experiment("LightGBM_Baseline", config.__dict__)

# è®°å½•æŒ‡æ ‡
exp.log_metric("rmse", rmse)
exp.log_metric("mae", mae)
exp.log_metric("accuracy", accuracy)

# ä¿å­˜ç»“æœ
exp.save_results()
exp.save_dataframe(predictions_df, "predictions.csv")
```

#### 2. å®éªŒæ¯”è¾ƒ

```python
# åŠ è½½å†å²å®éªŒ
exp1 = Experiment.load_experiment("experiments/LightGBM_Baseline_20241201_120000")
exp2 = Experiment.load_experiment("experiments/LightGBM_Tuned_20241201_130000")

# æ¯”è¾ƒå®éªŒ
comparison_fig = exp1.compare_experiments([exp2], "rmse")
```

## âš™ï¸ é…ç½®è¯´æ˜

### ğŸ“‹ ä¸»è¦é…ç½®å‚æ•°

#### æ•°æ®é…ç½®
```python
class Config:
    # æ•°æ®è·¯å¾„
    base_dir = "/path/to/ml-latest-small"  # æ•°æ®é›†æ ¹ç›®å½•
    save_dir = "output"                     # è¾“å‡ºç›®å½•
    
    # æ•°æ®æ–‡ä»¶
    ratings_file = "ratings.csv"           # è¯„åˆ†æ–‡ä»¶
    movies_file = "movies.csv"             # ç”µå½±æ–‡ä»¶
    tags_file = "tags.csv"                 # æ ‡ç­¾æ–‡ä»¶
```

#### ç‰¹å¾å·¥ç¨‹é…ç½®
```python
    # ç‰¹å¾å‚æ•°
    latent_dim = 20        # SVDéšå› å­ç»´åº¦
    tfidf_dim = 100        # TF-IDFç‰¹å¾ç»´åº¦
    num_classes = 10       # è¯„åˆ†ç±»åˆ«æ•° (0.5-5.0, æ­¥é•¿0.5)
```

#### æ¨¡å‹é…ç½®
```python
    # LightGBMå‚æ•°
    n_estimators = 1000    # æ ‘çš„æ•°é‡
    learning_rate = 0.05   # å­¦ä¹ ç‡
    num_leaves = 63        # å¶å­èŠ‚ç‚¹æ•°
    seed = 42              # éšæœºç§å­
```

#### é¢„å¤„ç†é…ç½®
```python
    # å¼‚å¸¸å€¼æ£€æµ‹
    outlier_detection_enabled = True
    outlier_handling_strategy = 'flag'  # 'flag', 'remove', 'cap'
    
    # è¯„åˆ†èŒƒå›´
    rating_min = 0.5
    rating_max = 5.0
```

### ğŸ”§ è‡ªå®šä¹‰é…ç½®

#### åˆ›å»ºè‡ªå®šä¹‰é…ç½®ç±»

```python
from config import Config

class CustomConfig(Config):
    def __init__(self):
        super().__init__()
        # è‡ªå®šä¹‰å‚æ•°
        self.n_estimators = 500
        self.learning_rate = 0.1
        self.latent_dim = 50
        
        # è‡ªå®šä¹‰æ•°æ®è·¯å¾„
        self.base_dir = "/custom/data/path"
        
        # éªŒè¯é…ç½®
        self.validate_config()

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
custom_config = CustomConfig()
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MOVIE_DATA_DIR="/path/to/data"
export MOVIE_OUTPUT_DIR="/path/to/output"
export MOVIE_N_ESTIMATORS=500
```

```python
# åœ¨ä»£ç ä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡
import os

class EnvConfig(Config):
    def __init__(self):
        super().__init__()
        self.base_dir = os.getenv('MOVIE_DATA_DIR', self.base_dir)
        self.save_dir = os.getenv('MOVIE_OUTPUT_DIR', self.save_dir)
        self.n_estimators = int(os.getenv('MOVIE_N_ESTIMATORS', self.n_estimators))
```

## ğŸ“š APIæ–‡æ¡£

### ğŸ”Œ æ ¸å¿ƒAPI

#### æ•°æ®åŠ è½½API

```python
def load_data(enable_preprocessing: bool = True, 
              outlier_strategy: str = 'flag') -> Tuple[pd.DataFrame, ...]:
    """
    åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    
    Args:
        enable_preprocessing: æ˜¯å¦å¯ç”¨æ•°æ®é¢„å¤„ç†
        outlier_strategy: å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥
    
    Returns:
        ratings, movies, tags, preprocessing_report
    """
```

#### ç‰¹å¾å·¥ç¨‹API

```python
def create_collaborative_filtering_features(ratings: pd.DataFrame) -> Tuple[...]:
    """
    åˆ›å»ºååŒè¿‡æ»¤ç‰¹å¾
    
    Args:
        ratings: è¯„åˆ†æ•°æ®
    
    Returns:
        user_factors, item_factors, user_bias, item_bias
    """

def create_content_features(movies: pd.DataFrame) -> Tuple[...]:
    """
    åˆ›å»ºå†…å®¹ç‰¹å¾
    
    Args:
        movies: ç”µå½±æ•°æ®
    
    Returns:
        movie_features, label_binarizer
    """
```

#### æ¨¡å‹è®­ç»ƒAPI

```python
def train_models(X_train: np.ndarray, 
                y_train: np.ndarray,
                num_classes: int = 10,
                **kwargs) -> List[LGBMClassifier]:
    """
    è®­ç»ƒåºæ•°åˆ†ç±»æ¨¡å‹
    
    Args:
        X_train: è®­ç»ƒç‰¹å¾
        y_train: è®­ç»ƒæ ‡ç­¾
        num_classes: ç±»åˆ«æ•°é‡
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        è®­ç»ƒå¥½çš„æ¨¡å‹åˆ—è¡¨
    """

def predict(models: List[LGBMClassifier], 
           X_val: np.ndarray) -> np.ndarray:
    """
    æ¨¡å‹é¢„æµ‹
    
    Args:
        models: è®­ç»ƒå¥½çš„æ¨¡å‹åˆ—è¡¨
        X_val: éªŒè¯ç‰¹å¾
    
    Returns:
        é¢„æµ‹æ ‡ç­¾
    """
```

#### å¯è§†åŒ–API

```python
def plot_error_distribution(output_df: pd.DataFrame, 
                           save_path: Optional[str] = None,
                           **kwargs) -> Optional[plt.Figure]:
    """
    ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒå›¾
    
    Args:
        output_df: é¢„æµ‹ç»“æœæ•°æ®
        save_path: ä¿å­˜è·¯å¾„
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        matplotlibå›¾è¡¨å¯¹è±¡
    """
```

### ğŸ› ï¸ å·¥å…·å‡½æ•°API

#### è¯„ä¼°æŒ‡æ ‡

```python
def compute_rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """è®¡ç®—RMSE"""

def rmse_by_class(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[float, float]:
    """è®¡ç®—å„ç±»åˆ«çš„RMSE"""

def user_error_distribution(output_df: pd.DataFrame) -> pd.DataFrame:
    """è®¡ç®—ç”¨æˆ·è¯¯å·®åˆ†å¸ƒ"""
```

#### æ¨¡å‹å·¥å…·

```python
def rating_to_label(rating: float) -> int:
    """è¯„åˆ†è½¬æ¢ä¸ºæ ‡ç­¾"""

def label_to_rating(label: int) -> float:
    """æ ‡ç­¾è½¬æ¢ä¸ºè¯„åˆ†"""

def generate_ordinal_targets(y: np.ndarray, num_classes: int) -> np.ndarray:
    """ç”Ÿæˆåºæ•°åˆ†ç±»ç›®æ ‡"""
```

## ğŸ§ª å®éªŒç®¡ç†

### ğŸ“Š å®éªŒè®°å½•

ç³»ç»Ÿæä¾›å®Œæ•´çš„å®éªŒç®¡ç†åŠŸèƒ½ï¼Œè‡ªåŠ¨è®°å½•æ¯æ¬¡å®éªŒçš„é…ç½®ã€ç»“æœå’Œäº§ç‰©ï¼š

#### å®éªŒç›®å½•ç»“æ„
```
experiments/
â””â”€â”€ LightGBM_CORAL_MovieLens_20241201_120000/
    â”œâ”€â”€ config.json          # å®éªŒé…ç½®
    â”œâ”€â”€ results.json         # å®éªŒç»“æœ
    â”œâ”€â”€ predictions.csv      # é¢„æµ‹ç»“æœ
    â”œâ”€â”€ plots/              # å¯è§†åŒ–å›¾è¡¨
    â”‚   â”œâ”€â”€ error_analysis/
    â”‚   â”œâ”€â”€ feature_analysis/
    â”‚   â””â”€â”€ prediction_plots/
    â”œâ”€â”€ models/             # è®­ç»ƒæ¨¡å‹
    â”‚   â””â”€â”€ lightgbm_models.pkl
    â””â”€â”€ logs/               # å®éªŒæ—¥å¿—
        â””â”€â”€ experiment.log
```

#### å®éªŒé…ç½®ç¤ºä¾‹
```json
{
  "experiment_id": "LightGBM_CORAL_MovieLens_20241201_120000",
  "timestamp": "2024-12-01 12:00:00",
  "model_name": "LightGBM_CORAL",
  "parameters": {
    "n_estimators": 1000,
    "learning_rate": 0.05,
    "num_leaves": 63,
    "latent_dim": 20,
    "tfidf_dim": 100
  },
  "data_info": {
    "dataset": "MovieLens-latest-small",
    "train_size": 80000,
    "val_size": 20000,
    "feature_count": 150
  }
}
```

#### å®éªŒç»“æœç¤ºä¾‹
```json
{
  "metrics": {
    "rmse": 0.8542,
    "mae": 0.6731,
    "accuracy": 0.3456,
    "precision": 0.3421,
    "recall": 0.3456,
    "f1_score": 0.3438
  },
  "execution_time": 1234.56,
  "feature_importance": {
    "user_bias": 0.1234,
    "item_bias": 0.1123,
    "movie_avg_rating": 0.0987
  }
}
```

### ğŸ“ˆ å®éªŒæ¯”è¾ƒ

#### æ¯”è¾ƒå¤šä¸ªå®éªŒ

```python
from experiments.experiment import Experiment

# åŠ è½½å®éªŒ
exp1 = Experiment.load_experiment("experiments/Baseline_20241201_120000")
exp2 = Experiment.load_experiment("experiments/Tuned_20241201_130000")
exp3 = Experiment.load_experiment("experiments/Advanced_20241201_140000")

# åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
comparison_fig = exp1.compare_experiments([exp2, exp3], "rmse")

# ç”Ÿæˆæ¯”è¾ƒæŠ¥å‘Š
comparison_report = {
    "experiments": [exp1.experiment_id, exp2.experiment_id, exp3.experiment_id],
    "rmse": [exp1.results.get("rmse"), exp2.results.get("rmse"), exp3.results.get("rmse")],
    "best_experiment": min([exp1, exp2, exp3], key=lambda x: x.results.get("rmse", float('inf'))).experiment_id
}
```

#### å®éªŒè¿½è¸ª

```python
# æŸ¥çœ‹å®éªŒå†å²
experiment_history = Experiment.list_experiments()
print(f"æ€»å®éªŒæ•°: {len(experiment_history)}")

# æŸ¥æ‰¾æœ€ä½³å®éªŒ
best_exp = min(experiment_history, key=lambda x: x.get_metric("rmse"))
print(f"æœ€ä½³å®éªŒ: {best_exp.experiment_id}, RMSE: {best_exp.get_metric('rmse')}")

# å®éªŒè¶‹åŠ¿åˆ†æ
rmse_trend = [exp.get_metric("rmse") for exp in experiment_history]
time_trend = [exp.timestamp for exp in experiment_history]

plt.plot(time_trend, rmse_trend)
plt.title("RMSEæ”¹è¿›è¶‹åŠ¿")
plt.xlabel("æ—¶é—´")
plt.ylabel("RMSE")
plt.show()
```

## ğŸ“Š æ€§èƒ½è¯„ä¼°

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡

#### å›å½’æŒ‡æ ‡
- **RMSE (Root Mean Square Error)**: å‡æ–¹æ ¹è¯¯å·®ï¼Œä¸»è¦è¯„ä¼°æŒ‡æ ‡
- **MAE (Mean Absolute Error)**: å¹³å‡ç»å¯¹è¯¯å·®
- **RÂ² (R-squared)**: å†³å®šç³»æ•°ï¼Œè§£é‡Šæ–¹å·®æ¯”ä¾‹
- **MAPE (Mean Absolute Percentage Error)**: å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®

#### åˆ†ç±»æŒ‡æ ‡
- **Accuracy**: å‡†ç¡®ç‡ï¼Œå®Œå…¨æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- **Precision**: ç²¾ç¡®ç‡ï¼Œå„ç±»åˆ«çš„é¢„æµ‹ç²¾åº¦
- **Recall**: å¬å›ç‡ï¼Œå„ç±»åˆ«çš„è¦†ç›–ç‡
- **F1-Score**: F1åˆ†æ•°ï¼Œç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡

#### æ’åºæŒ‡æ ‡
- **NDCG (Normalized Discounted Cumulative Gain)**: å½’ä¸€åŒ–æŠ˜æŸç´¯ç§¯å¢ç›Š
- **MAP (Mean Average Precision)**: å¹³å‡ç²¾åº¦å‡å€¼
- **MRR (Mean Reciprocal Rank)**: å¹³å‡å€’æ•°æ’å

### ğŸ“ˆ æ€§èƒ½åŸºå‡†

#### MovieLens-latest-small æ•°æ®é›†åŸºå‡†

| æ¨¡å‹ | RMSE | MAE | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ |
|------|------|-----|--------|----------|
| **LightGBM-CORAL** | **0.854** | **0.673** | **34.6%** | **~5åˆ†é’Ÿ** |
| Random Forest | 0.892 | 0.701 | 32.1% | ~8åˆ†é’Ÿ |
| SVD | 0.873 | 0.688 | 33.2% | ~2åˆ†é’Ÿ |
| KNN | 0.921 | 0.734 | 29.8% | ~15åˆ†é’Ÿ |
| Baseline (å‡å€¼) | 1.126 | 0.943 | 18.7% | ~1ç§’ |

#### åˆ†å±‚æ€§èƒ½åˆ†æ

**æŒ‰è¯„åˆ†ç­‰çº§çš„RMSE**
| è¯„åˆ† | RMSE | æ ·æœ¬æ•° | å æ¯” |
|------|------|--------|------|
| 0.5-1.0 | 0.721 | 1,234 | 1.2% |
| 1.5-2.0 | 0.756 | 3,456 | 3.5% |
| 2.5-3.0 | 0.834 | 12,345 | 12.3% |
| 3.5-4.0 | 0.867 | 34,567 | 34.6% |
| 4.5-5.0 | 0.892 | 48,398 | 48.4% |

**æŒ‰ç”¨æˆ·æ´»è·ƒåº¦çš„æ€§èƒ½**
| ç”¨æˆ·ç±»å‹ | è¯„åˆ†æ•°èŒƒå›´ | RMSE | ç”¨æˆ·æ•° |
|----------|------------|------|--------|
| æ–°ç”¨æˆ· | 1-10 | 0.923 | 45,123 |
| æ™®é€šç”¨æˆ· | 11-50 | 0.854 | 23,456 |
| æ´»è·ƒç”¨æˆ· | 51-200 | 0.798 | 3,456 |
| è¶…çº§ç”¨æˆ· | 200+ | 0.743 | 234 |

### ğŸ” æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### æ¨¡å‹å±‚é¢ä¼˜åŒ–
1. **è¶…å‚æ•°è°ƒä¼˜**: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–
2. **ç‰¹å¾é€‰æ‹©**: ç§»é™¤ä½é‡è¦æ€§ç‰¹å¾ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
3. **æ¨¡å‹é›†æˆ**: ç»“åˆå¤šç§ç®—æ³•çš„é¢„æµ‹ç»“æœ
4. **æ­£åˆ™åŒ–**: å¢åŠ L1/L2æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ

#### ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–
1. **æ·±åº¦ç‰¹å¾**: å¢åŠ ç”¨æˆ·è¡Œä¸ºåºåˆ—ç‰¹å¾
2. **æ—¶é—´ç‰¹å¾**: è€ƒè™‘è¯„åˆ†æ—¶é—´çš„å‘¨æœŸæ€§æ¨¡å¼
3. **äº¤å‰ç‰¹å¾**: åˆ›å»ºæ›´å¤šç”¨æˆ·-ç‰©å“äº¤äº’ç‰¹å¾
4. **å¤–éƒ¨ç‰¹å¾**: é›†æˆç”µå½±ç¥¨æˆ¿ã€æ¼”å‘˜ä¿¡æ¯ç­‰

#### æ•°æ®å±‚é¢ä¼˜åŒ–
1. **æ•°æ®å¢å¼º**: ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯æ‰©å……è®­ç»ƒé›†
2. **é‡‡æ ·ç­–ç•¥**: å¹³è¡¡ä¸åŒè¯„åˆ†ç­‰çº§çš„æ ·æœ¬åˆ†å¸ƒ
3. **å™ªå£°å¤„ç†**: è¯†åˆ«å’Œå¤„ç†æ ‡æ³¨å™ªå£°
4. **å†·å¯åŠ¨**: æ”¹è¿›æ–°ç”¨æˆ·å’Œæ–°ç‰©å“çš„å¤„ç†ç­–ç•¥

## ğŸ¨ å¯è§†åŒ–åˆ†æ

### ğŸ“Š å›¾è¡¨ç±»å‹

#### 1. é¢„æµ‹æ•ˆæœå›¾è¡¨

**çœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾**
```python
from visualization.basic_plots import plot_boxplot_true_vs_pred

# ç”Ÿæˆç®±çº¿å›¾
fig = plot_boxplot_true_vs_pred(predictions_df)
```
- å±•ç¤ºé¢„æµ‹å‡†ç¡®æ€§
- è¯†åˆ«ç³»ç»Ÿæ€§åå·®
- è¯„ä¼°ä¸åŒè¯„åˆ†ç­‰çº§çš„é¢„æµ‹è´¨é‡

**é¢„æµ‹è¯„åˆ†åˆ†å¸ƒç›´æ–¹å›¾**
```python
from visualization.basic_plots import plot_predicted_rating_hist

# ç”Ÿæˆåˆ†å¸ƒå›¾
fig = plot_predicted_rating_hist(predictions_df)
```
- åˆ†æé¢„æµ‹ç»“æœçš„åˆ†å¸ƒç‰¹å¾
- æ£€æŸ¥é¢„æµ‹èŒƒå›´çš„åˆç†æ€§
- è¯†åˆ«é¢„æµ‹åå¥½æ¨¡å¼

#### 2. è¯¯å·®åˆ†æå›¾è¡¨

**è¯¯å·®åˆ†å¸ƒå›¾**
```python
from visualization.error_analysis import plot_error_distribution

# ç”Ÿæˆè¯¯å·®åˆ†å¸ƒå›¾
fig = plot_error_distribution(predictions_df, show_stats=True)
```
- åˆ†æé¢„æµ‹è¯¯å·®çš„ç»Ÿè®¡ç‰¹æ€§
- è¯†åˆ«å¼‚å¸¸è¯¯å·®æ¨¡å¼
- è¯„ä¼°æ¨¡å‹çš„ç¨³å®šæ€§

**æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾**
```python
from visualization.error_analysis import plot_confusion_heatmap

# ç”Ÿæˆæ··æ·†çŸ©é˜µ
fig = plot_confusion_heatmap(predictions_df, normalize='true')
```
- åˆ†æåˆ†ç±»å‡†ç¡®æ€§
- è¯†åˆ«å®¹æ˜“æ··æ·†çš„è¯„åˆ†ç­‰çº§
- è¯„ä¼°é¢„æµ‹åå·®æ¨¡å¼

**ç”¨æˆ·è¯¯å·®åˆ†å¸ƒ**
```python
from visualization.error_analysis import plot_user_error_distribution

# ç”Ÿæˆç”¨æˆ·è¯¯å·®åˆ†å¸ƒ
fig = plot_user_error_distribution(predictions_df)
```
- åˆ†æä¸åŒç”¨æˆ·çš„é¢„æµ‹å‡†ç¡®æ€§
- è¯†åˆ«éš¾ä»¥é¢„æµ‹çš„ç”¨æˆ·ç¾¤ä½“
- ä¼˜åŒ–ä¸ªæ€§åŒ–æ¨èç­–ç•¥

#### 3. ç‰¹å¾åˆ†æå›¾è¡¨

**ç‰¹å¾é‡è¦æ€§å›¾**
```python
from visualization.feature_plots import plot_top20_feature_importance

# ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾
fig = plot_top20_feature_importance(models, X_train, feature_names)
```
- è¯†åˆ«æœ€é‡è¦çš„ç‰¹å¾
- æŒ‡å¯¼ç‰¹å¾å·¥ç¨‹ä¼˜åŒ–
- æä¾›æ¨¡å‹è§£é‡Šæ€§

**ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾**
```python
from visualization.feature_plots import plot_feature_correlation

# ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾
fig = plot_feature_correlation(df, feature_columns, target='rating')
```
- åˆ†æç‰¹å¾é—´çš„ç›¸å…³æ€§
- è¯†åˆ«å†—ä½™ç‰¹å¾
- å‘ç°ç‰¹å¾ç»„åˆæœºä¼š

**ç‰¹å¾åˆ†å¸ƒå›¾**
```python
from visualization.feature_plots import plot_feature_distributions

# ç”Ÿæˆç‰¹å¾åˆ†å¸ƒå›¾
fig = plot_feature_distributions(df, feature_columns)
```
- åˆ†æç‰¹å¾çš„åˆ†å¸ƒç‰¹å¾
- è¯†åˆ«å¼‚å¸¸å€¼å’Œåæ–œ
- æŒ‡å¯¼ç‰¹å¾é¢„å¤„ç†

#### 4. æ—¶é—´åºåˆ—åˆ†æ

**è¯„åˆ†è¶‹åŠ¿åˆ†æ**
```python
from visualization.error_analysis import plot_error_by_year

# ç”Ÿæˆæ—¶é—´è¶‹åŠ¿å›¾
fig = plot_error_by_year(predictions_df, df, val_indices)
```
- åˆ†æè¯„åˆ†éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿
- è¯†åˆ«å­£èŠ‚æ€§æ¨¡å¼
- è¯„ä¼°æ¨¡å‹çš„æ—¶é—´ç¨³å®šæ€§

**çƒ­åº¦ç›¸å…³æ€§åˆ†æ**
```python
from visualization.error_analysis import plot_error_vs_popularity

# ç”Ÿæˆçƒ­åº¦ç›¸å…³æ€§å›¾
fig = plot_error_vs_popularity(predictions_df, movie_stats)
```
- åˆ†æé¢„æµ‹è¯¯å·®ä¸ç”µå½±çƒ­åº¦çš„å…³ç³»
- è¯†åˆ«å†·é—¨ç”µå½±çš„é¢„æµ‹éš¾åº¦
- ä¼˜åŒ–é•¿å°¾æ¨èç­–ç•¥

### ğŸ¨ å›¾è¡¨å®šåˆ¶

#### æ ·å¼é…ç½®
```python
# è®¾ç½®å…¨å±€æ ·å¼
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.size'] = 12
plt.rcParams['figure.figsize'] = (10, 8)
sns.set_style("whitegrid")
sns.set_palette("husl")
```

#### è‡ªå®šä¹‰é¢œè‰²
```python
# è‡ªå®šä¹‰é¢œè‰²æ–¹æ¡ˆ
custom_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
sns.set_palette(custom_colors)
```

#### äº¤äº’å¼å›¾è¡¨
```python
import plotly.express as px
import plotly.graph_objects as go

# åˆ›å»ºäº¤äº’å¼æ•£ç‚¹å›¾
fig = px.scatter(predictions_df, 
                x='true_rating', 
                y='pred_rating',
                color='error',
                hover_data=['userId', 'movieId'],
                title='äº¤äº’å¼é¢„æµ‹æ•ˆæœå›¾')
fig.show()
```

## â“ å¸¸è§é—®é¢˜

### ğŸ”§ å®‰è£…é—®é¢˜

**Q: å®‰è£…LightGBMæ—¶å‡ºç°ç¼–è¯‘é”™è¯¯ï¼Ÿ**

A: å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š
```bash
# æ–¹æ¡ˆ1: ä½¿ç”¨condaå®‰è£…
conda install -c conda-forge lightgbm

# æ–¹æ¡ˆ2: å®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install --prefer-binary lightgbm

# æ–¹æ¡ˆ3: å®‰è£…ä¾èµ–åé‡è¯•
# Windows:
pip install cmake
# macOS:
brew install cmake
# Ubuntu:
sudo apt-get install cmake
```

**Q: å¯¼å…¥æ¨¡å—æ—¶å‡ºç°è·¯å¾„é”™è¯¯ï¼Ÿ**

A: ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­ï¼š
```python
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
```

### ğŸ“Š æ•°æ®é—®é¢˜

**Q: æ•°æ®æ–‡ä»¶æ‰¾ä¸åˆ°ï¼Ÿ**

A: æ£€æŸ¥æ•°æ®è·¯å¾„é…ç½®ï¼š
```python
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
import os
from config import config

print(f"æ•°æ®ç›®å½•: {config.base_dir}")
print(f"è¯„åˆ†æ–‡ä»¶å­˜åœ¨: {os.path.exists(config.ratings_file)}")
print(f"ç”µå½±æ–‡ä»¶å­˜åœ¨: {os.path.exists(config.movies_file)}")
```

**Q: å†…å­˜ä¸è¶³é”™è¯¯ï¼Ÿ**

A: ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼š
```python
# å‡å°‘ç‰¹å¾ç»´åº¦
config.latent_dim = 10
config.tfidf_dim = 50

# ä½¿ç”¨æ•°æ®é‡‡æ ·
ratings_sample = ratings.sample(frac=0.5, random_state=42)

# åˆ†æ‰¹å¤„ç†
from sklearn.model_selection import train_test_split
X_train, X_temp = train_test_split(X, test_size=0.5, random_state=42)
```

### ğŸ¤– æ¨¡å‹é—®é¢˜

**Q: è®­ç»ƒæ—¶é—´è¿‡é•¿ï¼Ÿ**

A: ä¼˜åŒ–è®­ç»ƒå‚æ•°ï¼š
```python
# å‡å°‘æ ‘çš„æ•°é‡
config.n_estimators = 100

# å¢åŠ å­¦ä¹ ç‡
config.learning_rate = 0.1

# å‡å°‘å¶å­èŠ‚ç‚¹æ•°
config.num_leaves = 31

# å¯ç”¨æ—©åœ
early_stopping_rounds = 50
```

**Q: é¢„æµ‹ç»“æœä¸ç†æƒ³ï¼Ÿ**

A: å°è¯•ä»¥ä¸‹ä¼˜åŒ–ç­–ç•¥ï¼š
```python
# 1. å¢åŠ ç‰¹å¾å·¥ç¨‹
# 2. è°ƒæ•´æ¨¡å‹å‚æ•°
# 3. ä½¿ç”¨äº¤å‰éªŒè¯
# 4. æ£€æŸ¥æ•°æ®è´¨é‡
# 5. å°è¯•ç‰¹å¾é€‰æ‹©
```

### ğŸ“ˆ å¯è§†åŒ–é—®é¢˜

**Q: å›¾è¡¨æ˜¾ç¤ºä¹±ç ï¼Ÿ**

A: é…ç½®ä¸­æ–‡å­—ä½“ï¼š
```python
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
```

**Q: å›¾è¡¨ä¿å­˜å¤±è´¥ï¼Ÿ**

A: æ£€æŸ¥ä¿å­˜è·¯å¾„å’Œæƒé™ï¼š
```python
import os

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(config.save_dir, exist_ok=True)

# æ£€æŸ¥å†™å…¥æƒé™
test_file = os.path.join(config.save_dir, 'test.txt')
try:
    with open(test_file, 'w') as f:
        f.write('test')
    os.remove(test_file)
    print("å†™å…¥æƒé™æ­£å¸¸")
except Exception as e:
    print(f"å†™å…¥æƒé™é”™è¯¯: {e}")
```

### ğŸ§ª å®éªŒé—®é¢˜

**Q: å®éªŒç»“æœæ— æ³•å¤ç°ï¼Ÿ**

A: ç¡®ä¿éšæœºç§å­è®¾ç½®ï¼š
```python
import random
import numpy as np
from sklearn.utils import check_random_state

# è®¾ç½®å…¨å±€éšæœºç§å­
random.seed(42)
np.random.seed(42)
config.seed = 42

# åœ¨æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨ç›¸åŒç§å­
models = train_models(X_train, y_train, seed=42)
```

**Q: å®éªŒè®°å½•ä¸¢å¤±ï¼Ÿ**

A: æ£€æŸ¥å®éªŒç›®å½•å’Œå¤‡ä»½ï¼š
```python
# åˆ—å‡ºæ‰€æœ‰å®éªŒ
experiments = os.listdir('experiments')
print(f"å®éªŒæ•°é‡: {len(experiments)}")

# å¤‡ä»½é‡è¦å®éªŒ
import shutil
shutil.copytree('experiments/important_exp', 'backup/important_exp')
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### ğŸ“‹ è´¡çŒ®æ–¹å¼

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- ğŸ› **BugæŠ¥å‘Š**: å‘ç°å¹¶æŠ¥å‘Šç³»ç»Ÿä¸­çš„é—®é¢˜
- ğŸ’¡ **åŠŸèƒ½å»ºè®®**: æå‡ºæ–°åŠŸèƒ½æˆ–æ”¹è¿›å»ºè®®
- ğŸ“ **æ–‡æ¡£æ”¹è¿›**: å®Œå–„æ–‡æ¡£å’Œæ•™ç¨‹
- ğŸ”§ **ä»£ç è´¡çŒ®**: æäº¤ä»£ç ä¿®å¤æˆ–æ–°åŠŸèƒ½
- ğŸ§ª **æµ‹è¯•ç”¨ä¾‹**: æ·»åŠ æµ‹è¯•ç”¨ä¾‹æé«˜ä»£ç è´¨é‡
- ğŸ“Š **æ•°æ®é›†**: è´¡çŒ®æ–°çš„æ•°æ®é›†æˆ–åŸºå‡†æµ‹è¯•

### ğŸ”„ å¼€å‘æµç¨‹

#### 1. ç¯å¢ƒå‡†å¤‡
```bash
# Forké¡¹ç›®åˆ°ä½ çš„GitHubè´¦æˆ·
# å…‹éš†ä½ çš„Fork
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system

# æ·»åŠ ä¸Šæ¸¸ä»“åº“
git remote add upstream https://github.com/original-repo/movie-recommendation-system.git

# åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/your-feature-name
```

#### 2. å¼€å‘è§„èŒƒ

**ä»£ç é£æ ¼**
- éµå¾ªPEP 8 Pythonä»£ç è§„èŒƒ
- ä½¿ç”¨æœ‰æ„ä¹‰çš„å˜é‡å’Œå‡½æ•°å
- æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- ä¿æŒä»£ç ç®€æ´å’Œå¯è¯»æ€§

**æäº¤è§„èŒƒ**
```bash
# æäº¤ä¿¡æ¯æ ¼å¼
git commit -m "type(scope): description"

# ç¤ºä¾‹
git commit -m "feat(models): add ensemble learning support"
git commit -m "fix(data): resolve memory leak in data loading"
git commit -m "docs(readme): update installation guide"
```

**ç±»å‹è¯´æ˜**
- `feat`: æ–°åŠŸèƒ½
- `fix`: Bugä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼è°ƒæ•´
- `refactor`: ä»£ç é‡æ„
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»ºæˆ–è¾…åŠ©å·¥å…·å˜åŠ¨

#### 3. æµ‹è¯•è¦æ±‚

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_models.py -v

# æ£€æŸ¥ä»£ç è¦†ç›–ç‡
python -m pytest --cov=. tests/

# ä»£ç é£æ ¼æ£€æŸ¥
flake8 .
black --check .
```

#### 4. æäº¤Pull Request

1. **ç¡®ä¿ä»£ç è´¨é‡**
   - æ‰€æœ‰æµ‹è¯•é€šè¿‡
   - ä»£ç é£æ ¼ç¬¦åˆè§„èŒƒ
   - æ·»åŠ å¿…è¦çš„æ–‡æ¡£

2. **åˆ›å»ºPull Request**
   - æä¾›æ¸…æ™°çš„æ ‡é¢˜å’Œæè¿°
   - è¯´æ˜å˜æ›´çš„åŸå› å’Œå½±å“
   - å…³è”ç›¸å…³çš„Issue

3. **ä»£ç å®¡æŸ¥**
   - å“åº”å®¡æŸ¥æ„è§
   - åŠæ—¶ä¿®å¤é—®é¢˜
   - ä¿æŒæ²Ÿé€š

### ğŸ“ å¼€å‘æŒ‡å—

#### æ·»åŠ æ–°ç‰¹å¾

```python
# 1. åœ¨data/data_loader.pyä¸­æ·»åŠ ç‰¹å¾æå–å‡½æ•°
def create_new_features(data: pd.DataFrame) -> pd.DataFrame:
    """
    åˆ›å»ºæ–°çš„ç‰¹å¾
    
    Args:
        data: è¾“å…¥æ•°æ®
    
    Returns:
        åŒ…å«æ–°ç‰¹å¾çš„DataFrame
    """
    # å®ç°ç‰¹å¾æå–é€»è¾‘
    pass

# 2. åœ¨main.pyä¸­é›†æˆæ–°ç‰¹å¾
new_features = create_new_features(df)
df = pd.concat([df, new_features], axis=1)

# 3. æ›´æ–°ç‰¹å¾åˆ—è¡¨
feature_columns.extend(new_features.columns.tolist())
```

#### æ·»åŠ æ–°æ¨¡å‹

```python
# 1. åœ¨models/ç›®å½•ä¸‹åˆ›å»ºæ–°æ¨¡å‹æ–‡ä»¶
# models/new_model.py
class NewModel:
    def __init__(self, **kwargs):
        self.params = kwargs
    
    def fit(self, X, y):
        # å®ç°è®­ç»ƒé€»è¾‘
        pass
    
    def predict(self, X):
        # å®ç°é¢„æµ‹é€»è¾‘
        pass

# 2. åœ¨models/train_eval.pyä¸­é›†æˆæ–°æ¨¡å‹
from .new_model import NewModel

def train_new_model(X_train, y_train, **kwargs):
    model = NewModel(**kwargs)
    model.fit(X_train, y_train)
    return model
```

#### æ·»åŠ æ–°å¯è§†åŒ–

```python
# 1. åœ¨visualization/ç›®å½•ä¸‹æ·»åŠ æ–°å›¾è¡¨å‡½æ•°
def plot_new_analysis(data, save_path=None):
    """
    åˆ›å»ºæ–°çš„åˆ†æå›¾è¡¨
    
    Args:
        data: åˆ†ææ•°æ®
        save_path: ä¿å­˜è·¯å¾„
    
    Returns:
        matplotlibå›¾è¡¨å¯¹è±¡
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    # å®ç°ç»˜å›¾é€»è¾‘
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    
    return fig

# 2. åœ¨main.pyä¸­è°ƒç”¨æ–°å›¾è¡¨
from visualization.new_plots import plot_new_analysis
plot_new_analysis(analysis_data, 'output/new_analysis.png')
```

### ğŸ§ª æµ‹è¯•æŒ‡å—

#### ç¼–å†™å•å…ƒæµ‹è¯•

```python
# tests/test_new_feature.py
import unittest
import pandas as pd
from data.data_loader import create_new_features

class TestNewFeatures(unittest.TestCase):
    def setUp(self):
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        self.test_data = pd.DataFrame({
            'userId': [1, 2, 3],
            'movieId': [1, 2, 3],
            'rating': [4.0, 3.5, 5.0]
        })
    
    def test_create_new_features(self):
        # æµ‹è¯•æ–°ç‰¹å¾åˆ›å»º
        features = create_new_features(self.test_data)
        self.assertIsInstance(features, pd.DataFrame)
        self.assertGreater(len(features.columns), 0)
    
    def test_feature_values(self):
        # æµ‹è¯•ç‰¹å¾å€¼çš„åˆç†æ€§
        features = create_new_features(self.test_data)
        self.assertFalse(features.isnull().any().any())

if __name__ == '__main__':
    unittest.main()
```

#### é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
import unittest
from main import main

class TestIntegration(unittest.TestCase):
    def test_full_pipeline(self):
        # æµ‹è¯•å®Œæ•´æµç¨‹
        try:
            main()
            self.assertTrue(True)
        except Exception as e:
            self.fail(f"Pipeline failed with error: {e}")
```

## ğŸ“ˆ æ›´æ–°æ—¥å¿—

### ç‰ˆæœ¬ 2.0.0 (2024-12-01)

#### ğŸ‰ æ–°åŠŸèƒ½
- âœ¨ æ·»åŠ åºæ•°åˆ†ç±»æ”¯æŒï¼Œæå‡è¯„åˆ†é¢„æµ‹å‡†ç¡®æ€§
- ğŸ”§ é‡æ„ç‰¹å¾å·¥ç¨‹æ¨¡å—ï¼Œæ”¯æŒæ›´å¤šç‰¹å¾ç±»å‹
- ğŸ“Š æ–°å¢20+ç§å¯è§†åŒ–å›¾è¡¨å’Œåˆ†æå·¥å…·
- ğŸ§ª å®Œæ•´çš„å®éªŒç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
- ğŸ“š å…¨é¢çš„APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

#### ğŸš€ æ€§èƒ½ä¼˜åŒ–
- âš¡ ä¼˜åŒ–LightGBMè®­ç»ƒå‚æ•°ï¼Œæå‡è®­ç»ƒé€Ÿåº¦30%
- ğŸ’¾ æ”¹è¿›å†…å­˜ä½¿ç”¨ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®é›†
- ğŸ”„ å¹¶è¡ŒåŒ–ç‰¹å¾å·¥ç¨‹ï¼Œå‡å°‘å¤„ç†æ—¶é—´
- ğŸ“ˆ ä¼˜åŒ–é¢„æµ‹æµç¨‹ï¼Œæå‡æ¨ç†é€Ÿåº¦

#### ğŸ› Bugä¿®å¤
- ğŸ”§ ä¿®å¤LightGBM APIå…¼å®¹æ€§é—®é¢˜
- ğŸ“Š ä¿®å¤å¯è§†åŒ–å›¾è¡¨ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
- ğŸ’¾ ä¿®å¤å¤§æ•°æ®é›†å†…å­˜æº¢å‡ºé—®é¢˜
- ğŸ” ä¿®å¤ç‰¹å¾é‡è¦æ€§è®¡ç®—é”™è¯¯

#### ğŸ“ æ–‡æ¡£æ”¹è¿›
- ğŸ“š å®Œå–„READMEæ–‡æ¡£ï¼Œæ·»åŠ è¯¦ç»†ä½¿ç”¨æŒ‡å—
- ğŸ¯ æ–°å¢å¿«é€Ÿå¼€å§‹æ•™ç¨‹
- ğŸ“– æ·»åŠ APIæ–‡æ¡£å’Œä»£ç ç¤ºä¾‹
- ğŸ”§ å®Œå–„å®‰è£…å’Œé…ç½®è¯´æ˜

### ç‰ˆæœ¬ 1.5.0 (2024-11-15)

#### ğŸ‰ æ–°åŠŸèƒ½
- ğŸ”§ æ·»åŠ æ•°æ®é¢„å¤„ç†å’Œå¼‚å¸¸å€¼æ£€æµ‹
- ğŸ“Š æ–°å¢ç”¨æˆ·å’Œç”µå½±ç”»åƒç‰¹å¾
- ğŸ¨ æ”¹è¿›å¯è§†åŒ–å›¾è¡¨æ ·å¼å’Œäº¤äº’æ€§
- ğŸ“ æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ç³»ç»Ÿ

#### ğŸš€ æ€§èƒ½ä¼˜åŒ–
- âš¡ ä¼˜åŒ–SVDçŸ©é˜µåˆ†è§£ç®—æ³•
- ğŸ’¾ æ”¹è¿›æ•°æ®åŠ è½½å’Œç¼“å­˜æœºåˆ¶
- ğŸ”„ ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹æµç¨‹

### ç‰ˆæœ¬ 1.0.0 (2024-10-01)

#### ğŸ‰ åˆå§‹ç‰ˆæœ¬
- ğŸ¤– åŸºç¡€LightGBMæ¨¡å‹å®ç°
- ğŸ“Š ååŒè¿‡æ»¤å’Œå†…å®¹ç‰¹å¾
- ğŸ¨ åŸºç¡€å¯è§†åŒ–åŠŸèƒ½
- ğŸ“ é¡¹ç›®åŸºç¡€æ¶æ„

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

### è®¸å¯è¯æ‘˜è¦

```
MIT License

Copyright (c) 2024 Movie Recommendation System

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®å’Œè´¡çŒ®è€…ï¼š

- **MovieLensæ•°æ®é›†**: GroupLens Researchæä¾›çš„é«˜è´¨é‡ç”µå½±è¯„åˆ†æ•°æ®
- **LightGBM**: Microsoftå¼€å‘çš„é«˜æ•ˆæ¢¯åº¦æå‡æ¡†æ¶
- **scikit-learn**: æœºå™¨å­¦ä¹ å·¥å…·åº“
- **pandas**: æ•°æ®å¤„ç†å’Œåˆ†æåº“
- **matplotlib/seaborn**: æ•°æ®å¯è§†åŒ–åº“
- **å¼€æºç¤¾åŒº**: æ‰€æœ‰è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜å’Œæä¾›å»ºè®®çš„å¼€å‘è€…

## ğŸ“ è”ç³»æˆ‘ä»¬

- **é¡¹ç›®ä¸»é¡µ**: [GitHub Repository](https://github.com/your-username/movie-recommendation-system)
- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/your-username/movie-recommendation-system/issues)
- **åŠŸèƒ½è¯·æ±‚**: [GitHub Discussions](https://github.com/your-username/movie-recommendation-system/discussions)
- **é‚®ç®±**: your-email@example.com
- **æ–‡æ¡£**: [åœ¨çº¿æ–‡æ¡£](https://your-username.github.io/movie-recommendation-system/)

## ğŸŒŸ Star History

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª â­ Starï¼

[![Star History Chart](https://api.star-history.com/svg?repos=your-username/movie-recommendation-system&type=Date)](https://star-history.com/#your-username/movie-recommendation-system&Date)

---

<div align="center">
  <p><strong>ğŸ¬ è®©æˆ‘ä»¬ä¸€èµ·æ„å»ºæ›´å¥½çš„ç”µå½±æ¨èç³»ç»Ÿï¼</strong></p>
  <p>Made with â¤ï¸ by the Movie Recommendation Team</p>
</div>