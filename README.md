# ç”µå½±æ¨èç³»ç»Ÿ (Movie Recommendation System)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![LightGBM](https://img.shields.io/badge/LightGBM-Latest-green.svg)](https://lightgbm.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Development-orange.svg)]()

è¿™æ˜¯ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„ç”µå½±è¯„åˆ†é¢„æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨åºæ•°åˆ†ç±»ç®—æ³•é¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†ã€‚ç³»ç»Ÿé›†æˆäº†å¤šç§ç‰¹å¾å·¥ç¨‹æŠ€æœ¯å’Œå¯è§†åŒ–åˆ†æå·¥å…·ï¼Œä¸ºç”µå½±æ¨èæä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

## ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨è¯´æ˜](#è¯¦ç»†ä½¿ç”¨è¯´æ˜)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [APIæ–‡æ¡£](#apiæ–‡æ¡£)
- [å®éªŒç®¡ç†](#å®éªŒç®¡ç†)
- [æ€§èƒ½è¯„ä¼°](#æ€§èƒ½è¯„ä¼°)
- [å¯è§†åŒ–åˆ†æ](#å¯è§†åŒ–åˆ†æ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)
- [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)
- [è®¸å¯è¯](#è®¸å¯è¯)

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªç”µå½±è¯„åˆ†é¢„æµ‹ç³»ç»Ÿï¼Œæ—¨åœ¨å‡†ç¡®é¢„æµ‹ç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ†åå¥½ã€‚é‡‡ç”¨åºæ•°åˆ†ç±»æŠ€æœ¯ï¼Œå°†è¯„åˆ†é¢„æµ‹è½¬åŒ–ä¸ºå¤šä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ›´å¥½åœ°ä¿æŒè¯„åˆ†ä¹‹é—´çš„é¡ºåºå…³ç³»ã€‚

### é€‚ç”¨åœºæ™¯

- **ç”µå½±æ¨èå¹³å°**: ä¸ºç”¨æˆ·æ¨èå¯èƒ½å–œæ¬¢çš„ç”µå½±
- **å†…å®¹åˆ†æ**: åˆ†æç”µå½±è´¨é‡è¶‹åŠ¿å’Œè§‚ä¼—åå¥½
- **ä¸ªæ€§åŒ–æœåŠ¡**: åŸºäºç”¨æˆ·è§‚å½±å†å²æä¾›ä¸ªæ€§åŒ–æ¨è
- **å­¦æœ¯ç ”ç©¶**: æ¨èç³»ç»Ÿå’Œæœºå™¨å­¦ä¹ ç ”ç©¶çš„å®éªŒå¹³å°

### æ ¸å¿ƒä¼˜åŠ¿

- **ç®—æ³•å…ˆè¿›**: é‡‡ç”¨LightGBMåºæ•°åˆ†ç±»æŠ€æœ¯ï¼Œä¿æŒè¯„åˆ†çš„é¡ºåºç‰¹æ€§
- **ç‰¹å¾ä¸°å¯Œ**: èåˆååŒè¿‡æ»¤ã€å†…å®¹åˆ†æã€æ–‡æœ¬æŒ–æ˜ç­‰å¤šç§ç‰¹å¾
- **å¯è§†åŒ–å®Œå–„**: æä¾›å¤šç§å›¾è¡¨è¿›è¡Œæ•°æ®åˆ†æå’Œç»“æœå±•ç¤º
- **å®éªŒç®¡ç†**: å®Œæ•´çš„å®éªŒè®°å½•å’Œè¿½è¸ªç³»ç»Ÿ
- **æ¨¡å—åŒ–è®¾è®¡**: æ˜“äºæ‰©å±•å’Œç»´æŠ¤çš„ä»£ç æ¶æ„

## æ ¸å¿ƒç‰¹æ€§

### ç‰¹å¾å·¥ç¨‹

- **ååŒè¿‡æ»¤ç‰¹å¾**: é€šè¿‡SVDçŸ©é˜µåˆ†è§£ï¼ŒæŒ–æ˜ç”¨æˆ·å’Œç”µå½±çš„å…³è”æ¨¡å¼
- **å†…å®¹ç‰¹å¾**: ä»ç”µå½±çš„ç±»å‹ã€å¹´ä»½ç­‰ä¿¡æ¯ä¸­æå–ç»“æ„åŒ–ç‰¹å¾
- **æ–‡æœ¬ç‰¹å¾**: åˆ©ç”¨TF-IDFæŠ€æœ¯åˆ†æç”¨æˆ·æ ‡ç­¾åå¥½
- **ç”¨æˆ·ç”»åƒ**: åˆ†æç”¨æˆ·çš„è¯„åˆ†ä¹ æƒ¯å’Œåå¥½å€¾å‘
- **ç”µå½±ç”»åƒ**: è¯„ä¼°ç”µå½±çš„è´¨é‡æŒ‡æ ‡å’Œå—æ¬¢è¿ç¨‹åº¦
- **äº¤å‰ç‰¹å¾**: æ•æ‰ç”¨æˆ·ä¸ç”µå½±çš„äº’åŠ¨æ¨¡å¼

### æ ¸å¿ƒç®—æ³•

- **åºæ•°åˆ†ç±»**: é‡‡ç”¨CORALé£æ ¼çš„å¤šåˆ†ç±»å™¨æ¶æ„ï¼Œå¤„ç†è¯„åˆ†çš„æœ‰åºæ€§
- **LightGBM**: ä½¿ç”¨æ¢¯åº¦æå‡å†³ç­–æ ‘ï¼Œå…¼é¡¾å‡†ç¡®æ€§å’Œé€Ÿåº¦
- **ç‰¹å¾é€‰æ‹©**: è‡ªåŠ¨è¯†åˆ«é‡è¦ç‰¹å¾ï¼Œæå‡æ¨¡å‹æ•ˆæœ
- **å‚æ•°è°ƒä¼˜**: æ”¯æŒç½‘æ ¼æœç´¢ï¼Œæ‰¾åˆ°æœ€ä½³å‚æ•°ç»„åˆ

### è¯„ä¼°ä½“ç³»

- **å›å½’æŒ‡æ ‡**: ä½¿ç”¨RMSEã€MAEã€RÂ²ç­‰æŒ‡æ ‡è¡¡é‡é¢„æµ‹ç²¾åº¦
- **åˆ†ç±»æŒ‡æ ‡**: é€šè¿‡å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1-Scoreè¯„ä¼°åˆ†ç±»æ•ˆæœ
- **åˆ†å±‚åˆ†æ**: åˆ†æä¸åŒç”¨æˆ·ç¾¤ä½“ã€ç”µå½±ç±»å‹çš„æ¨¡å‹è¡¨ç°
- **è¯¯å·®è¯Šæ–­**: è¯†åˆ«é¢„æµ‹åå·®æ¨¡å¼ï¼Œå‘ç°å¼‚å¸¸æƒ…å†µ

### å¯è§†åŒ–åˆ†æ

- **é¢„æµ‹æ•ˆæœå±•ç¤º**: æ•£ç‚¹å›¾å’Œç®±çº¿å›¾å¯¹æ¯”çœŸå®å€¼ä¸é¢„æµ‹å€¼
- **è¯¯å·®åˆ†æ**: è¯¯å·®åˆ†å¸ƒè§„å¾‹ã€æ··æ·†çŸ©é˜µå’Œç”¨æˆ·è¯¯å·®æ¨¡å¼
- **ç‰¹å¾åˆ†æ**: ç‰¹å¾é‡è¦æ€§æ’åºã€ç›¸å…³æ€§çƒ­åŠ›å›¾å’Œæ•°æ®åˆ†å¸ƒ
- **æ—¶é—´è¶‹åŠ¿åˆ†æ**: è¯„åˆ†çš„æ—¶é—´å˜åŒ–è§„å¾‹
- **ç”¨æˆ·è¡Œä¸ºåˆ†æ**: ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼å’Œåå¥½ç‰¹å¾

## æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”µå½±æ¨èç³»ç»Ÿæ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å±‚ (Data Layer)                                        â”‚
â”‚  â”œâ”€â”€ MovieLensæ•°æ®é›† (ratings.csv, movies.csv, tags.csv)    â”‚
â”‚  â”œâ”€â”€ æ•°æ®é¢„å¤„ç† (å¼‚å¸¸å€¼æ£€æµ‹, æ•°æ®æ¸…æ´—)                        â”‚
â”‚  â””â”€â”€ æ•°æ®è´¨é‡æ§åˆ¶ (å®Œæ•´æ€§æ£€æŸ¥, æ ¼å¼éªŒè¯)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç‰¹å¾å±‚ (Feature Layer)                                     â”‚
â”‚  â”œâ”€â”€ ååŒè¿‡æ»¤ç‰¹å¾ (SVDçŸ©é˜µåˆ†è§£)                              â”‚
â”‚  â”œâ”€â”€ å†…å®¹ç‰¹å¾ (ç”µå½±ç±»å‹, å¹´ä»½)                               â”‚
â”‚  â”œâ”€â”€ æ–‡æœ¬ç‰¹å¾ (TF-IDFæ ‡ç­¾ç‰¹å¾)                               â”‚
â”‚  â”œâ”€â”€ ç”¨æˆ·ç”»åƒ (è¯„åˆ†è¡Œä¸º, åå¥½æ¨¡å¼)                           â”‚
â”‚  â”œâ”€â”€ ç”µå½±ç”»åƒ (è´¨é‡æŒ‡æ ‡, çƒ­åº¦ç‰¹å¾)                           â”‚
â”‚  â””â”€â”€ äº¤å‰ç‰¹å¾ (ç”¨æˆ·-ç‰©å“äº¤äº’)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¨¡å‹å±‚ (Model Layer)                                       â”‚
â”‚  â”œâ”€â”€ åºæ•°åˆ†ç±»å™¨ (å¤šä¸ªLightGBMäºŒåˆ†ç±»å™¨)                       â”‚
â”‚  â”œâ”€â”€ ç‰¹å¾é€‰æ‹© (é‡è¦æ€§åˆ†æ)                                   â”‚
â”‚  â”œâ”€â”€ è¶…å‚æ•°ä¼˜åŒ– (ç½‘æ ¼æœç´¢)                                   â”‚
â”‚  â””â”€â”€ æ¨¡å‹é›†æˆ (æŠ•ç¥¨æœºåˆ¶)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¯„ä¼°å±‚ (Evaluation Layer)                                  â”‚
â”‚  â”œâ”€â”€ å¤šæŒ‡æ ‡è¯„ä¼° (RMSE, MAE, å‡†ç¡®ç‡ç­‰)                        â”‚
â”‚  â”œâ”€â”€ åˆ†å±‚åˆ†æ (ç”¨æˆ·ç¾¤ä½“, ç”µå½±ç±»å‹)                           â”‚
â”‚  â”œâ”€â”€ è¯¯å·®åˆ†æ (é¢„æµ‹åå·®, å¼‚å¸¸æ£€æµ‹)                           â”‚
â”‚  â””â”€â”€ æ€§èƒ½ç›‘æ§ (è®­ç»ƒæ›²çº¿, éªŒè¯æ›²çº¿)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¯è§†åŒ–å±‚ (Visualization Layer)                             â”‚
â”‚  â”œâ”€â”€ é¢„æµ‹æ•ˆæœå›¾è¡¨ (æ•£ç‚¹å›¾, ç®±çº¿å›¾)                           â”‚
â”‚  â”œâ”€â”€ è¯¯å·®åˆ†æå›¾è¡¨ (åˆ†å¸ƒå›¾, çƒ­åŠ›å›¾)                           â”‚
â”‚  â”œâ”€â”€ ç‰¹å¾åˆ†æå›¾è¡¨ (é‡è¦æ€§, ç›¸å…³æ€§)                           â”‚
â”‚  â””â”€â”€ æ—¶é—´åºåˆ—å›¾è¡¨ (è¶‹åŠ¿åˆ†æ)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åº”ç”¨å±‚ (Application Layer)                                 â”‚
â”‚  â”œâ”€â”€ å®éªŒç®¡ç† (ç‰ˆæœ¬æ§åˆ¶, ç»“æœè¿½è¸ª)                           â”‚
â”‚  â”œâ”€â”€ é…ç½®ç®¡ç† (å‚æ•°è®¾ç½®, ç¯å¢ƒé…ç½®)                           â”‚
â”‚  â”œâ”€â”€ æ—¥å¿—ç³»ç»Ÿ (è¿è¡Œæ—¥å¿—, é”™è¯¯è¿½è¸ª)                           â”‚
â”‚  â””â”€â”€ APIæ¥å£ (é¢„æµ‹æœåŠ¡, æ¨¡å‹ç®¡ç†)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## é¡¹ç›®ç»“æ„

```
2025_ML_Code/
â”œâ”€â”€ README.md                    # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ config.py                    # å…¨å±€é…ç½®ç®¡ç†
â”œâ”€â”€ main.py                      # ä¸»ç¨‹åºå…¥å£
â”‚
â”œâ”€â”€ data/                        # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ data_loader.py           # æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ data_preprocessing.py    # æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—
â”‚   â”œâ”€â”€ movies.csv               # ç”µå½±ä¿¡æ¯æ•°æ®
â”‚   â”œâ”€â”€ ratings.csv              # ç”¨æˆ·è¯„åˆ†æ•°æ®
â”‚   â””â”€â”€ tags.csv                 # ç”¨æˆ·æ ‡ç­¾æ•°æ®
â”‚
â”œâ”€â”€ models/                      # æ¨¡å‹ç›¸å…³æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ train_eval.py            # æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
â”‚   â””â”€â”€ model_utils.py           # æ¨¡å‹å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ utils/                       # å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ logger.py                # æ—¥å¿—è®°å½•å·¥å…·
â”‚   â””â”€â”€ metrics.py               # è¯„ä¼°æŒ‡æ ‡å‡½æ•°
â”‚
â”œâ”€â”€ visualization/               # å¯è§†åŒ–æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ basic_plots.py           # åŸºç¡€å›¾è¡¨
â”‚   â”œâ”€â”€ error_analysis.py        # è¯¯å·®åˆ†æå›¾è¡¨
â”‚   â””â”€â”€ feature_plots.py         # ç‰¹å¾åˆ†æå›¾è¡¨
â”‚
â”œâ”€â”€ experiments/                 # å®éªŒç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ experiment.py            # å®éªŒç®¡ç†ç±»
â”‚   â””â”€â”€ [å®éªŒè®°å½•ç›®å½•]/           # å„æ¬¡å®éªŒçš„ç»“æœ
â”‚       â”œâ”€â”€ config.json          # å®éªŒé…ç½®
â”‚       â”œâ”€â”€ results.json         # å®éªŒç»“æœ
â”‚       â”œâ”€â”€ predictions.csv      # é¢„æµ‹ç»“æœ
â”‚       â”œâ”€â”€ plots/               # å¯è§†åŒ–å›¾è¡¨
â”‚       â”œâ”€â”€ models/              # è®­ç»ƒæ¨¡å‹
â”‚       â””â”€â”€ logs/                # å®éªŒæ—¥å¿—
â”‚
â”œâ”€â”€ output/                      # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ predictions.csv          # æœ€æ–°é¢„æµ‹ç»“æœ
â”‚   â””â”€â”€ *.png                    # ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
â”‚
â””â”€â”€ logs/                        # æ—¥å¿—ç›®å½•
    â””â”€â”€ *.log                    # è¿è¡Œæ—¥å¿—æ–‡ä»¶
```

### æ ¸å¿ƒæ¨¡å—è¯´æ˜

| æ¨¡å— | åŠŸèƒ½æè¿° | ä¸»è¦æ–‡ä»¶ |
|------|----------|----------|
| **config** | å…¨å±€é…ç½®ç®¡ç† | `config.py` |
| **data** | æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ | `data_loader.py`, `data_preprocessing.py` |
| **models** | æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼° | `train_eval.py`, `model_utils.py` |
| **utils** | å·¥å…·å‡½æ•°ã€æ—¥å¿—ã€è¯„ä¼°æŒ‡æ ‡ | `logger.py`, `metrics.py` |
| **visualization** | å¯è§†åŒ–åˆ†æå’Œå›¾è¡¨ç”Ÿæˆ | `basic_plots.py`, `error_analysis.py`, `feature_plots.py` |
| **experiments** | å®éªŒç®¡ç†å’Œç»“æœè¿½è¸ª | `experiment.py` |

## å®‰è£…æŒ‡å—

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.8æˆ–æ›´é«˜ç‰ˆæœ¬
- **æ“ä½œç³»ç»Ÿ**: Windows 10+ã€macOS 10.14+æˆ–Ubuntu 18.04+
- **å†…å­˜**: è‡³å°‘4GB RAM
- **å­˜å‚¨ç©ºé—´**: é¢„ç•™2GBå¯ç”¨ç©ºé—´

### ä¾èµ–åŒ…

#### æ ¸å¿ƒä¾èµ–
```
pandas>=1.3.0          # æ•°æ®å¤„ç†
numpy>=1.21.0           # æ•°å€¼è®¡ç®—
scikit-learn>=1.0.0     # æœºå™¨å­¦ä¹ å·¥å…·
lightgbm>=3.3.0         # æ¢¯åº¦æå‡æ¨¡å‹
scikit-surprise>=1.1.1  # æ¨èç³»ç»Ÿç®—æ³•
```

#### å¯è§†åŒ–ä¾èµ–
```
matplotlib>=3.5.0       # åŸºç¡€ç»˜å›¾
seaborn>=0.11.0         # ç»Ÿè®¡å›¾è¡¨
plotly>=5.0.0           # äº¤äº’å¼å›¾è¡¨
```

#### å·¥å…·ä¾èµ–
```
tqdm>=4.62.0            # è¿›åº¦æ¡
loguru>=0.6.0           # æ—¥å¿—ç®¡ç†
jupyter>=1.0.0          # äº¤äº’å¼å¼€å‘
```

### å®‰è£…æ­¥éª¤

#### æ–¹æ³•ä¸€ï¼špipå®‰è£…

```bash
# 1. ä¸‹è½½é¡¹ç›®ä»£ç 
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system

# 2. åˆ›å»ºPythonç¯å¢ƒ
python -m venv movie_rec_env

# 3. æ¿€æ´»ç¯å¢ƒ
# Windows:
movie_rec_env\Scripts\activate
# macOS/Linux:
source movie_rec_env/bin/activate

# 4. å®‰è£…ä¾èµ–
pip install --upgrade pip
pip install -r requirements.txt

# 5. æµ‹è¯•å®‰è£…
python -c "import lightgbm, pandas, sklearn; print('å®‰è£…æˆåŠŸï¼')"
```

#### æ–¹æ³•äºŒï¼šcondaå®‰è£…

```bash
# 1. åˆ›å»ºcondaç¯å¢ƒ
conda create -n movie_rec python=3.9
conda activate movie_rec

# 2. å®‰è£…ä¾èµ–åŒ…
conda install pandas numpy scikit-learn matplotlib seaborn
pip install lightgbm scikit-surprise tqdm loguru

# 3. è·å–é¡¹ç›®ä»£ç 
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system
```

### æ•°æ®å‡†å¤‡

#### è·å–MovieLensæ•°æ®é›†

ä½¿ç”¨MovieLensæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼š

```bash
# è‡ªåŠ¨ä¸‹è½½
python scripts/download_data.py

# æ‰‹åŠ¨ä¸‹è½½
# 1. è®¿é—® https://grouplens.org/datasets/movielens/
# 2. ä¸‹è½½ ml-latest-small.zip æ–‡ä»¶
# 3. è§£å‹åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹
```

#### æ•°æ®é›†ç»“æ„
```
data/
â”œâ”€â”€ ratings.csv         # ç”¨æˆ·è¯„åˆ†æ•°æ®
â”œâ”€â”€ movies.csv          # ç”µå½±ä¿¡æ¯æ•°æ®
â””â”€â”€ tags.csv            # ç”¨æˆ·æ ‡ç­¾æ•°æ®
```

### å®‰è£…éªŒè¯

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python -m pytest tests/ -v

# æˆ–è¿è¡Œå¿«é€Ÿæµ‹è¯•
python scripts/test_installation.py
```

## å¿«é€Ÿå¼€å§‹

### ä¸‰æ­¥å¼€å§‹é¢„æµ‹

```bash
# ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ•°æ®
ls data/  # ç¡®è®¤èƒ½çœ‹åˆ° ratings.csv, movies.csv, tags.csv

# ç¬¬äºŒæ­¥ï¼šå¯åŠ¨ç¨‹åº
python main.py

# ç¬¬ä¸‰æ­¥ï¼šæŸ¥çœ‹ç»“æœ
ls output/  # æµè§ˆç”Ÿæˆçš„é¢„æµ‹æ–‡ä»¶å’Œå¯è§†åŒ–å›¾è¡¨
```

### è¾“å‡ºç»“æœ

ç¨‹åºè¿è¡Œå®Œæˆåçš„è¾“å‡ºå†…å®¹ï¼š

- **predictions.csv**: é¢„æµ‹ç»“æœï¼ŒåŒ…å«æ¯ä¸ªç”¨æˆ·å¯¹æ¯éƒ¨ç”µå½±çš„è¯„åˆ†é¢„æµ‹
- **å¯è§†åŒ–å›¾è¡¨**: å¤šç§.pngæ ¼å¼çš„åˆ†æå›¾è¡¨
- **å®éªŒè®°å½•**: åœ¨`experiments/`ç›®å½•ä¸‹ä¿å­˜çš„å®Œæ•´å®éªŒè®°å½•

### å¯è§†åŒ–å›¾è¡¨

ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„åˆ†æå›¾è¡¨ï¼š

1. **é¢„æµ‹æ•ˆæœ**
   - `boxplot_true_vs_pred.png`: çœŸå®è¯„åˆ†ä¸é¢„æµ‹è¯„åˆ†å¯¹æ¯”
   - `predicted_rating_hist.png`: é¢„æµ‹è¯„åˆ†åˆ†å¸ƒ

2. **è¯¯å·®åˆ†æ**
   - `prediction_error_hist.png`: é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
   - `mean_error_per_rating.png`: ä¸åŒè¯„åˆ†ç­‰çº§çš„å¹³å‡è¯¯å·®
   - `confusion_heatmap.png`: é¢„æµ‹å‡†ç¡®æ€§æ··æ·†çŸ©é˜µ

3. **ç‰¹å¾åˆ†æ**
   - `top20_feature_importance.png`: æœ€é‡è¦çš„20ä¸ªç‰¹å¾
   - `feature_correlation_heatmap.png`: ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾

## è¯¦ç»†ä½¿ç”¨è¯´æ˜

### é…ç½®ç®¡ç†

ç³»ç»Ÿæä¾›çµæ´»çš„é…ç½®ç®¡ç†ï¼Œæ‰€æœ‰è®¾ç½®éƒ½é›†ä¸­åœ¨`config.py`æ–‡ä»¶ä¸­ï¼š

```python
from config import config

# æŸ¥çœ‹å½“å‰é…ç½®
print(f"æ¨¡å‹åç§°: {config.model_name}")
print(f"æ•°æ®è·¯å¾„: {config.base_dir}")
print(f"éšå› å­ç»´åº¦: {config.latent_dim}")

# è°ƒæ•´å‚æ•°
config.n_estimators = 500      # å¢åŠ æ ‘çš„æ•°é‡æå‡ç²¾åº¦
config.learning_rate = 0.1     # è°ƒæ•´å­¦ä¹ ç‡
```

### æ•°æ®å¤„ç†æµç¨‹

#### 1. æ•°æ®åŠ è½½ä¸æ¸…æ´—

åŠ è½½MovieLensæ•°æ®ï¼š

```python
from data.data_loader import load_data

# åŠ è½½æ‰€æœ‰æ•°æ®
ratings, movies, tags, report = load_data(
    enable_preprocessing=True,    # å¼€å¯æ•°æ®æ¸…æ´—
    outlier_strategy='flag'       # å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥
)

# æŸ¥çœ‹æ•°æ®è§„æ¨¡
print(f"è¯„åˆ†è®°å½•æ•°: {len(ratings):,} æ¡")
print(f"ç”µå½±æ•°é‡: {len(movies):,} éƒ¨")
print(f"æ•°æ®è´¨é‡è¯„åˆ†: {report['quality_score']:.2f}/10")
```

#### 2. ç‰¹å¾å·¥ç¨‹

ç³»ç»Ÿè‡ªåŠ¨æ„å»ºå¤šç»´åº¦ç‰¹å¾ï¼š

```python
from data.data_loader import (
    create_collaborative_filtering_features,
    create_content_features,
    create_tfidf_tag_features,
    create_user_profile_features,
    create_movie_profile_features
)

# ååŒè¿‡æ»¤ç‰¹å¾
user_f, item_f, user_bias, item_bias = create_collaborative_filtering_features(ratings)

# å†…å®¹ç‰¹å¾
movies_feats, mlb = create_content_features(movies)

# TF-IDFç‰¹å¾
rat_tag, tag_df = create_tfidf_tag_features(ratings, tags)

# ç”¨æˆ·ç”»åƒ
user_stats, user_genre_pref = create_user_profile_features(ratings, movies)

# ç”µå½±ç”»åƒ
movie_stats = create_movie_profile_features(ratings)
```

### æ¨¡å‹è®­ç»ƒ

#### 1. åŸºç¡€è®­ç»ƒ

ä½¿ç”¨åºæ•°åˆ†ç±»ç®—æ³•è¿›è¡Œè®­ç»ƒï¼š

```python
from models.train_eval import train_models, predict
from models.model_utils import rating_to_label, label_to_rating

# å‡†å¤‡è®­ç»ƒæ•°æ®
X_train = df[feature_columns].values
y_train = df['rating'].apply(rating_to_label).values

# å¯åŠ¨æ¨¡å‹è®­ç»ƒ
models = train_models(
    X_train, y_train,
    num_classes=10,           # è¯„åˆ†ç±»åˆ«æ•° (0.5-5.0)
    n_estimators=1000,        # æ ‘çš„æ•°é‡
    learning_rate=0.05        # å­¦ä¹ ç‡
)

# ç”Ÿæˆé¢„æµ‹ç»“æœ
pred_labels = predict(models, X_val)
pred_ratings = [label_to_rating(label) for label in pred_labels]
```

#### 2. é«˜çº§è®­ç»ƒé€‰é¡¹

è‡ªå®šä¹‰è®­ç»ƒå‚æ•°ï¼š

```python
# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
models = train_models(
    X_train, y_train,
    num_classes=10,
    n_estimators=1000,
    learning_rate=0.05,
    num_leaves=63,                              # å¶å­èŠ‚ç‚¹æ•°
    categorical_features=['year_r', 'month_r'], # åˆ†ç±»ç‰¹å¾
    verbose=True                                # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
)

# è·å–ç‰¹å¾é‡è¦æ€§
feature_importance = models[0].feature_importances_
top_features = sorted(zip(feature_names, feature_importance), 
                     key=lambda x: x[1], reverse=True)[:20]
print("æœ€é‡è¦çš„20ä¸ªç‰¹å¾:")
for i, (name, importance) in enumerate(top_features, 1):
    print(f"{i:2d}. {name}: {importance:.4f}")
```

### è¯„ä¼°å’Œå¯è§†åŒ–

#### 1. æ€§èƒ½è¯„ä¼°

```python
from utils.metrics import compute_rmse, rmse_by_class
from models.train_eval import evaluate_models

# åŸºç¡€æŒ‡æ ‡
rmse = compute_rmse(true_ratings, pred_ratings)
print(f"RMSE: {rmse:.4f}")

# åˆ†ç±»è¯„ä¼°
class_rmse = rmse_by_class(true_ratings, pred_ratings)
print(f"å„ç±»åˆ«RMSE: {class_rmse}")

# è¯¦ç»†è¯„ä¼°
eval_results = evaluate_models(models, X_val, y_val)
print(f"å‡†ç¡®ç‡: {eval_results['accuracy']:.4f}")
```

#### 2. å¯è§†åŒ–åˆ†æ

```python
from visualization.error_analysis import (
    plot_error_distribution,
    plot_confusion_heatmap,
    plot_user_error_distribution
)
from visualization.feature_plots import (
    plot_top20_feature_importance,
    plot_feature_correlation
)

# è¯¯å·®åˆ†æ
plot_error_distribution(predictions_df)
plot_confusion_heatmap(predictions_df)

# ç‰¹å¾åˆ†æ
plot_top20_feature_importance(models, X_train)
plot_feature_correlation(df, feature_columns, 'rating')
```

### å®éªŒç®¡ç†

#### 1. åˆ›å»ºå®éªŒ

```python
from experiments.experiment import Experiment

# åˆ›å»ºå®éªŒ
exp = Experiment("LightGBM_Baseline", config.__dict__)

# è®°å½•æŒ‡æ ‡
exp.log_metric("rmse", rmse)
exp.log_metric("mae", mae)
exp.log_metric("accuracy", accuracy)

# ä¿å­˜ç»“æœ
exp.save_results()
exp.save_dataframe(predictions_df, "predictions.csv")
```

#### 2. å®éªŒæ¯”è¾ƒ

```python
# åŠ è½½å†å²å®éªŒ
exp1 = Experiment.load_experiment("experiments/LightGBM_Baseline_20241201_120000")
exp2 = Experiment.load_experiment("experiments/LightGBM_Tuned_20241201_130000")

# æ¯”è¾ƒå®éªŒ
comparison_fig = exp1.compare_experiments([exp2], "rmse")
```

## é…ç½®è¯´æ˜

### æ ¸å¿ƒé…ç½®å‚æ•°

ç³»ç»Ÿçš„ä¸»è¦é…ç½®é€‰é¡¹ï¼š

| é…ç½®é¡¹ | ç±»å‹ | é»˜è®¤å€¼ | åŠŸèƒ½è¯´æ˜ |
|--------|------|--------|----------|
| `model_name` | str | "movie_recommendation" | å®éªŒåç§° |
| `base_dir` | str | "data" | æ•°æ®é›†å­˜æ”¾ç›®å½• |
| `latent_dim` | int | 20 | SVDéšå› å­ç»´åº¦ |
| `tfidf_dim` | int | 100 | TF-IDFæœ€å¤§ç‰¹å¾æ•° |
| `seed` | int | 42 | éšæœºç§å­ |
| `num_classes` | int | 10 | è¯„åˆ†ç±»åˆ«æ•° (0.5-5.0ï¼Œæ­¥é•¿0.5) |
| `n_estimators` | int | 1000 | LightGBMæ ‘çš„æ•°é‡ |
| `learning_rate` | float | 0.05 | å­¦ä¹ ç‡ |
| `num_leaves` | int | 63 | æ¯æ£µæ ‘çš„å¶å­èŠ‚ç‚¹æ•° |

#### æ•°æ®é…ç½®
```python
class Config:
    # æ•°æ®è·¯å¾„
    base_dir = "/path/to/ml-latest-small"  # æ•°æ®é›†æ ¹ç›®å½•
    save_dir = "output"                     # è¾“å‡ºç›®å½•
    
    # æ•°æ®æ–‡ä»¶
    ratings_file = "ratings.csv"           # è¯„åˆ†æ–‡ä»¶
    movies_file = "movies.csv"             # ç”µå½±æ–‡ä»¶
    tags_file = "tags.csv"                 # æ ‡ç­¾æ–‡ä»¶
```

#### ç‰¹å¾å·¥ç¨‹é…ç½®
```python
    # ç‰¹å¾å‚æ•°
    latent_dim = 20        # SVDéšå› å­ç»´åº¦
    tfidf_dim = 100        # TF-IDFç‰¹å¾ç»´åº¦
    num_classes = 10       # è¯„åˆ†ç±»åˆ«æ•° (0.5-5.0, æ­¥é•¿0.5)
```

#### æ¨¡å‹é…ç½®
```python
    # LightGBMå‚æ•°
    n_estimators = 1000    # æ ‘çš„æ•°é‡
    learning_rate = 0.05   # å­¦ä¹ ç‡
    num_leaves = 63        # å¶å­èŠ‚ç‚¹æ•°
    seed = 42              # éšæœºç§å­
```

#### é¢„å¤„ç†é…ç½®
```python
    # å¼‚å¸¸å€¼æ£€æµ‹
    outlier_detection_enabled = True
    outlier_handling_strategy = 'flag'  # 'flag', 'remove', 'cap'
    
    # è¯„åˆ†èŒƒå›´
    rating_min = 0.5
    rating_max = 5.0
```

### æ€§èƒ½è°ƒä¼˜æŒ‡å—

#### è¿½æ±‚æ›´é«˜ç²¾åº¦
è·å¾—æœ€ä½³é¢„æµ‹æ•ˆæœçš„é…ç½®ï¼š
```python
# ç²¾åº¦ä¼˜å…ˆé…ç½®
config.latent_dim = 50             # æ›´å¤šéšå› å­
config.tfidf_dim = 200             # æ›´ä¸°å¯Œçš„æ–‡æœ¬ç‰¹å¾
config.n_estimators = 2000         # æ›´å¤šå†³ç­–æ ‘
config.num_leaves = 127            # æ›´æ·±çš„æ ‘ç»“æ„
```

#### è¿½æ±‚æ›´å¿«é€Ÿåº¦
å¿«é€ŸéªŒè¯æˆ–å¤„ç†å¤§æ•°æ®é›†çš„é…ç½®ï¼š
```python
# é€Ÿåº¦ä¼˜å…ˆé…ç½®
config.latent_dim = 10             # è¾ƒå°‘éšå› å­
config.tfidf_dim = 50              # ç²¾ç®€æ–‡æœ¬ç‰¹å¾
config.n_estimators = 500          # è¾ƒå°‘æ ‘æ•°é‡
config.learning_rate = 0.1         # æ›´é«˜å­¦ä¹ ç‡
```

### è‡ªå®šä¹‰é…ç½®

#### åˆ›å»ºè‡ªå®šä¹‰é…ç½®ç±»

```python
from config import Config

class CustomConfig(Config):
    def __init__(self):
        super().__init__()
        # è‡ªå®šä¹‰å‚æ•°
        self.n_estimators = 500
        self.learning_rate = 0.1
        self.latent_dim = 50
        
        # è‡ªå®šä¹‰æ•°æ®è·¯å¾„
        self.base_dir = "/custom/data/path"
        
        # éªŒè¯é…ç½®
        self.validate_config()

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
custom_config = CustomConfig()
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MOVIE_DATA_DIR="/path/to/data"
export MOVIE_OUTPUT_DIR="/path/to/output"
export MOVIE_N_ESTIMATORS=500
```

```python
# åœ¨ä»£ç ä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡
import os

class EnvConfig(Config):
    def __init__(self):
        super().__init__()
        self.base_dir = os.getenv('MOVIE_DATA_DIR', self.base_dir)
        self.save_dir = os.getenv('MOVIE_OUTPUT_DIR', self.save_dir)
        self.n_estimators = int(os.getenv('MOVIE_N_ESTIMATORS', self.n_estimators))
```

## APIæ–‡æ¡£

### æ ¸å¿ƒæ¨¡å—è¯¦è§£

#### data.data_loader - æ•°æ®åŠ è½½æ¨¡å—

ç³»ç»Ÿçš„æ•°æ®å…¥å£ï¼Œè´Ÿè´£åŠ è½½å’Œé¢„å¤„ç†MovieLensæ•°æ®ï¼š

```python
def load_data(enable_preprocessing: bool = True, 
              outlier_strategy: str = 'flag') -> Tuple[pd.DataFrame, ...]:
    """
    åŠ è½½MovieLensæ•°æ®é›†å¹¶è¿›è¡Œé¢„å¤„ç†
    
    Args:
        enable_preprocessing: æ˜¯å¦å¯ç”¨æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
        outlier_strategy: å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ ('flag', 'remove', 'cap')
    
    Returns:
        tuple: (ratings, movies, tags, preprocessing_report)
               å››ä¸ªå¤„ç†å¥½çš„DataFrameå’Œè´¨é‡æŠ¥å‘Š
               
    ä½¿ç”¨ç¤ºä¾‹:
        ratings, movies, tags, report = load_data(
            enable_preprocessing=True,
            outlier_strategy='flag'
        )
        print(f"æ•°æ®è´¨é‡è¯„åˆ†: {report['quality_score']:.2f}/10")
    """
```

#### ç‰¹å¾å·¥ç¨‹API

```python
def create_collaborative_filtering_features(ratings: pd.DataFrame, 
                                          latent_dim: int = 20) -> Tuple[...]:
    """
    ä½¿ç”¨SVDçŸ©é˜µåˆ†è§£åˆ›å»ºååŒè¿‡æ»¤ç‰¹å¾
    
    é€šè¿‡åˆ†è§£ç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µï¼Œå‘ç°ç”¨æˆ·å’Œç”µå½±çš„æ½œåœ¨ç‰¹å¾å‘é‡ã€‚
    
    Args:
        ratings: åŒ…å«userId, movieId, ratingçš„è¯„åˆ†æ•°æ®
        latent_dim: éšå› å­ç»´åº¦
    
    Returns:
        tuple: åŒ…å«å››ä¸ªnumpyæ•°ç»„
            - user_factors: ç”¨æˆ·éšå› å­çŸ©é˜µ (n_users Ã— latent_dim)
            - item_factors: ç”µå½±éšå› å­çŸ©é˜µ (n_movies Ã— latent_dim)
            - user_bias: ç”¨æˆ·åç½®å‘é‡
            - item_bias: ç”µå½±åç½®å‘é‡
            
    æŠ€æœ¯ç»†èŠ‚:
        ä½¿ç”¨scikit-surpriseåº“çš„SVDç®—æ³•ï¼Œè‡ªåŠ¨å¤„ç†ç¨€ç–çŸ©é˜µ
    """

def create_content_features(movies: pd.DataFrame) -> Tuple[...]:
    """
    ä»ç”µå½±ä¿¡æ¯ä¸­æå–å†…å®¹ç‰¹å¾
    
    Args:
        movies: åŒ…å«movieId, title, genresçš„ç”µå½±æ•°æ®
    
    Returns:
        tuple: (movie_features, label_binarizer)
            - movie_features: ç”µå½±ç‰¹å¾çŸ©é˜µ
            - label_binarizer: ç±»å‹ç¼–ç å™¨
    """
```

#### models.train_eval - æ¨¡å‹è®­ç»ƒæ¨¡å—

ç³»ç»Ÿçš„æœºå™¨å­¦ä¹ æ ¸å¿ƒï¼Œå®ç°åºæ•°åˆ†ç±»ç®—æ³•ï¼š

```python
def train_models(X_train: np.ndarray, 
                y_train: np.ndarray,
                num_classes: int = 10,
                **kwargs) -> List[LGBMClassifier]:
    """
    è®­ç»ƒåŸºäºLightGBMçš„åºæ•°åˆ†ç±»æ¨¡å‹
    
    å°†Kç±»åºæ•°åˆ†ç±»é—®é¢˜è½¬æ¢ä¸ºK-1ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œ
    æ›´å¥½åœ°ä¿æŒè¯„åˆ†çš„é¡ºåºå…³ç³»ã€‚
    
    Args:
        X_train: è®­ç»ƒç‰¹å¾çŸ©é˜µ (n_samples Ã— n_features)
        y_train: è®­ç»ƒæ ‡ç­¾å‘é‡ (0åˆ°num_classes-1çš„æ•´æ•°)
        num_classes: è¯„åˆ†ç±»åˆ«æ€»æ•° (é»˜è®¤10ï¼Œå¯¹åº”0.5-5.0è¯„åˆ†)
        **kwargs: LightGBMçš„é¢å¤–å‚æ•°
            - n_estimators: æ ‘çš„æ•°é‡
            - learning_rate: å­¦ä¹ ç‡
            - num_leaves: å¶å­èŠ‚ç‚¹æ•°
            - verbose: æ˜¯å¦æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
    
    Returns:
        list: åŒ…å«num_classes-1ä¸ªè®­ç»ƒå¥½çš„LightGBMæ¨¡å‹
              æ¯ä¸ªæ¨¡å‹è´Ÿè´£ä¸€ä¸ªäºŒåˆ†ç±»ä»»åŠ¡
              
    ç®—æ³•ä¼˜åŠ¿:
        - ä¿æŒè¯„åˆ†çš„è‡ªç„¶é¡ºåºå…³ç³»
        - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
        - æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ
    """

def predict(models: List[LGBMClassifier], 
           X_val: np.ndarray) -> np.ndarray:
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
    
    å°†å¤šä¸ªäºŒåˆ†ç±»æ¨¡å‹çš„ç»“æœç»„åˆï¼Œå¾—åˆ°æœ€ç»ˆçš„åºæ•°åˆ†ç±»é¢„æµ‹ã€‚
    
    Args:
        models: è®­ç»ƒå¥½çš„LightGBMæ¨¡å‹åˆ—è¡¨
        X_val: æµ‹è¯•ç‰¹å¾çŸ©é˜µ (n_samples Ã— n_features)
    
    Returns:
        array: é¢„æµ‹çš„ç±»åˆ«æ ‡ç­¾ (0åˆ°num_classes-1çš„æ•´æ•°)
               å¯ä»¥é€šè¿‡label_to_ratingå‡½æ•°è½¬æ¢ä¸ºå®é™…è¯„åˆ†
               
    é¢„æµ‹æµç¨‹:
        1. æ¯ä¸ªäºŒåˆ†ç±»æ¨¡å‹è¾“å‡ºæ¦‚ç‡
        2. æ ¹æ®æ¦‚ç‡é˜ˆå€¼ç¡®å®šæœ€ç»ˆç±»åˆ«
        3. ç¡®ä¿é¢„æµ‹ç»“æœçš„é¡ºåºä¸€è‡´æ€§
    """
```

#### å¯è§†åŒ–API

```python
def plot_error_distribution(output_df: pd.DataFrame, 
                           save_path: Optional[str] = None,
                           **kwargs) -> Optional[plt.Figure]:
    """
    ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒå›¾
    
    Args:
        output_df: é¢„æµ‹ç»“æœæ•°æ®
        save_path: ä¿å­˜è·¯å¾„
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        matplotlibå›¾è¡¨å¯¹è±¡
    """
```

### å·¥å…·å‡½æ•°API

#### è¯„ä¼°æŒ‡æ ‡

```python
def compute_rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """è®¡ç®—RMSE"""

def rmse_by_class(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[float, float]:
    """è®¡ç®—å„ç±»åˆ«çš„RMSE"""

def user_error_distribution(output_df: pd.DataFrame) -> pd.DataFrame:
    """è®¡ç®—ç”¨æˆ·è¯¯å·®åˆ†å¸ƒ"""
```

#### æ¨¡å‹å·¥å…·

```python
def rating_to_label(rating: float) -> int:
    """è¯„åˆ†è½¬æ¢ä¸ºæ ‡ç­¾"""

def label_to_rating(label: int) -> float:
    """æ ‡ç­¾è½¬æ¢ä¸ºè¯„åˆ†"""

def generate_ordinal_targets(y: np.ndarray, num_classes: int) -> np.ndarray:
    """ç”Ÿæˆåºæ•°åˆ†ç±»ç›®æ ‡"""
```

## å®éªŒç®¡ç†

### å®éªŒè¿½è¸ª

ç³»ç»Ÿæä¾›å®éªŒç®¡ç†åŠŸèƒ½ï¼Œå¸®åŠ©ç®¡ç†å’Œæ¯”è¾ƒä¸åŒçš„æ¨¡å‹ç‰ˆæœ¬ï¼š

#### å®éªŒæ–‡ä»¶ç»„ç»‡
æ¯æ¬¡å®éªŒéƒ½ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„æ–‡ä»¶å¤¹ï¼ŒåŒ…å«æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼š
```
experiments/
â””â”€â”€ LightGBM_CORAL_MovieLens_20241201_120000/
    â”œâ”€â”€ config.json          # å®éªŒé…ç½®å‚æ•°
    â”œâ”€â”€ results.json         # æ€§èƒ½æŒ‡æ ‡ç»“æœ
    â”œâ”€â”€ predictions.csv      # è¯¦ç»†é¢„æµ‹ç»“æœ
    â”œâ”€â”€ plots/              # å¯è§†åŒ–å›¾è¡¨
    â”‚   â”œâ”€â”€ error_analysis/  #   è¯¯å·®åˆ†æå›¾
    â”‚   â”œâ”€â”€ feature_analysis/ #   ç‰¹å¾åˆ†æå›¾
    â”‚   â””â”€â”€ prediction_plots/ #   é¢„æµ‹æ•ˆæœå›¾
    â”œâ”€â”€ models/             # è®­ç»ƒå¥½çš„æ¨¡å‹
    â”‚   â””â”€â”€ lightgbm_models.pkl
    â””â”€â”€ logs/               # è¿è¡Œæ—¥å¿—
        â””â”€â”€ experiment.log
```

#### å®éªŒé…ç½®è®°å½•
ç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜æ¯æ¬¡å®éªŒçš„å®Œæ•´é…ç½®ï¼Œç¡®ä¿ç»“æœå¯é‡ç°ï¼š
```json
{
  "experiment_id": "LightGBM_CORAL_MovieLens_20241201_120000",
  "timestamp": "2024-12-01 12:00:00",
  "model_name": "LightGBM_CORAL",
  "parameters": {
    "n_estimators": 1000,     // å†³ç­–æ ‘æ•°é‡
    "learning_rate": 0.05,    // å­¦ä¹ ç‡
    "num_leaves": 63,         // å¶å­èŠ‚ç‚¹æ•°
    "latent_dim": 20,         // éšå› å­ç»´åº¦
    "tfidf_dim": 100          // æ–‡æœ¬ç‰¹å¾ç»´åº¦
  },
  "data_info": {
    "dataset": "MovieLens-latest-small",
    "train_size": 80000,      // è®­ç»ƒé›†å¤§å°
    "val_size": 20000,        // éªŒè¯é›†å¤§å°
    "feature_count": 150      // ç‰¹å¾æ€»æ•°
  }
}
```

#### å®éªŒç»“æœè®°å½•
æ¯æ¬¡å®éªŒçš„è¯¦ç»†æ€§èƒ½æŒ‡æ ‡éƒ½ä¼šè¢«è‡ªåŠ¨ä¿å­˜ï¼š
```json
{
  "metrics": {
    "rmse": 0.8542,           // å‡æ–¹æ ¹è¯¯å·® (è¶Šå°è¶Šå¥½)
    "mae": 0.6731,            // å¹³å‡ç»å¯¹è¯¯å·®
    "accuracy": 0.3456,       // é¢„æµ‹å‡†ç¡®ç‡
    "precision": 0.3421,      // ç²¾ç¡®ç‡
    "recall": 0.3456,         // å¬å›ç‡
    "f1_score": 0.3438        // F1åˆ†æ•°
  },
  "execution_time": 1234.56,  // æ€»æ‰§è¡Œæ—¶é—´(ç§’)
  "feature_importance": {
    "user_bias": 0.1234,      // ç”¨æˆ·åç½®é‡è¦æ€§
    "item_bias": 0.1123,      // ç”µå½±åç½®é‡è¦æ€§
    "movie_avg_rating": 0.0987 // ç”µå½±å¹³å‡è¯„åˆ†é‡è¦æ€§
  }
}
```

### å®éªŒå¯¹æ¯”åˆ†æ

#### å¤šå®éªŒæ¯”è¾ƒ

æ¯”è¾ƒä¸åŒå®éªŒçš„æ•ˆæœï¼Œæ‰¾å‡ºæœ€ä½³é…ç½®ï¼š

```python
from experiments.experiment import Experiment

# åŠ è½½å†å²å®éªŒ
exp1 = Experiment.load_experiment("experiments/Baseline_20241201_120000")    # åŸºçº¿æ¨¡å‹
exp2 = Experiment.load_experiment("experiments/Tuned_20241201_130000")      # è°ƒä¼˜æ¨¡å‹
exp3 = Experiment.load_experiment("experiments/Advanced_20241201_140000")   # é«˜çº§æ¨¡å‹

# ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾è¡¨
comparison_fig = exp1.compare_experiments([exp2, exp3], "rmse")
print("å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ")

# è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
comparison_report = {
    "experiments": [exp1.experiment_id, exp2.experiment_id, exp3.experiment_id],
    "rmse": [exp1.results.get("rmse"), exp2.results.get("rmse"), exp3.results.get("rmse")],
    "best_experiment": min([exp1, exp2, exp3], key=lambda x: x.results.get("rmse", float('inf'))).experiment_id
}
print(f"æœ€ä½³å®éªŒ: {comparison_report['best_experiment']}")
```

#### å®éªŒå†å²è¿½è¸ª

æŒæ¡å®éªŒè¿›å±•å’Œæ”¹è¿›è¶‹åŠ¿ï¼š

```python
# æŸ¥çœ‹æ‰€æœ‰å®éªŒå†å²
experiment_history = Experiment.list_experiments()
print(f"æ€»å®éªŒæ•°: {len(experiment_history)} ä¸ª")

# è‡ªåŠ¨æ‰¾å‡ºæœ€ä½³å®éªŒ
best_exp = min(experiment_history, key=lambda x: x.get_metric("rmse"))
print(f"æœ€ä½³å®éªŒ: {best_exp.experiment_id}")
print(f"æœ€ä½³RMSE: {best_exp.get_metric('rmse'):.4f}")

# å¯è§†åŒ–æ”¹è¿›è¶‹åŠ¿
rmse_trend = [exp.get_metric("rmse") for exp in experiment_history]
time_trend = [exp.timestamp for exp in experiment_history]

plt.plot(time_trend, rmse_trend, marker='o', linewidth=2)
plt.title("æ¨¡å‹æ€§èƒ½æ”¹è¿›è¶‹åŠ¿")
plt.xlabel("å®éªŒæ—¶é—´")
plt.ylabel("RMSEå€¼")
plt.grid(True, alpha=0.3)
plt.show()
print("è¶‹åŠ¿å›¾å·²æ˜¾ç¤º")
```

## æ€§èƒ½è¯„ä¼°

### è¯„ä¼°ä½“ç³»

æä¾›ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»å¤šä¸ªè§’åº¦å…¨é¢è¡¡é‡æ¨¡å‹è¡¨ç°ï¼š

#### å›å½’æ€§èƒ½æŒ‡æ ‡
- **RMSE (å‡æ–¹æ ¹è¯¯å·®)**: è¡¡é‡é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„æ•´ä½“åå·®ï¼Œè¶Šå°è¶Šå¥½ï¼Œæ˜¯ä¸»è¦è¯„ä¼°æŒ‡æ ‡
- **MAE (å¹³å‡ç»å¯¹è¯¯å·®)**: åæ˜ é¢„æµ‹è¯¯å·®çš„å¹³å‡æ°´å¹³ï¼Œæ›´ç›´è§‚æ˜“æ‡‚
- **RÂ² (å†³å®šç³»æ•°)**: è§£é‡Šæ–¹å·®æ¯”ä¾‹ï¼Œæ˜¾ç¤ºæ¨¡å‹çš„è§£é‡Šèƒ½åŠ›
- **MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®)**: ç›¸å¯¹è¯¯å·®æŒ‡æ ‡ï¼Œä¾¿äºä¸åŒè§„æ¨¡æ•°æ®çš„æ¯”è¾ƒ

#### åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- **Accuracy (å‡†ç¡®ç‡)**: å®Œå…¨æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹ï¼Œå±•ç°æ¨¡å‹çš„ç²¾å‡†åº¦
- **Precision (ç²¾ç¡®ç‡)**: å„ç±»åˆ«çš„é¢„æµ‹ç²¾åº¦ï¼Œé¿å…è¯¯æŠ¥
- **Recall (å¬å›ç‡)**: å„ç±»åˆ«çš„è¦†ç›–ç‡ï¼Œé¿å…æ¼æŠ¥
- **F1-Score**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼Œå¹³è¡¡ä¸¤è€…å…³ç³»

#### æ¨èç³»ç»Ÿä¸“ç”¨æŒ‡æ ‡
- **NDCG (å½’ä¸€åŒ–æŠ˜æŸç´¯ç§¯å¢ç›Š)**: è€ƒè™‘æ’åºä½ç½®çš„æ¨èè´¨é‡è¯„ä¼°
- **MAP (å¹³å‡ç²¾åº¦å‡å€¼)**: æ¨èåˆ—è¡¨çš„æ•´ä½“ç²¾åº¦
- **MRR (å¹³å‡å€’æ•°æ’å)**: ç¬¬ä¸€ä¸ªç›¸å…³ç»“æœçš„æ’åè´¨é‡

### æ€§èƒ½åŸºå‡†æµ‹è¯•

#### MovieLensæ•°æ®é›†æ€§èƒ½å¯¹æ¯”

åœ¨æ ‡å‡†MovieLens-latest-smallæ•°æ®é›†ä¸Šçš„è¡¨ç°å¯¹æ¯”ï¼š

| ç®—æ³•æ¨¡å‹ | RMSE | MAE | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | ç»¼åˆè¯„ä»· |
|----------|------|-----|--------|----------|----------|
| **LightGBM-CORAL** | **0.854** | **0.673** | **34.6%** | **~5åˆ†é’Ÿ** | **æœ€ä½³å¹³è¡¡** |
| Random Forest | 0.892 | 0.701 | 32.1% | ~8åˆ†é’Ÿ | ç¨³å®šå¯é  |
| SVD | 0.873 | 0.688 | 33.2% | ~2åˆ†é’Ÿ | é€Ÿåº¦æœ€å¿« |
| KNN | 0.921 | 0.734 | 29.8% | ~15åˆ†é’Ÿ | è§£é‡Šæ€§å¼º |
| Baseline (å‡å€¼) | 1.126 | 0.943 | 18.7% | ~1ç§’ | åŸºå‡†å¯¹æ¯” |

#### æ·±åº¦æ€§èƒ½åˆ†æ

**ä¸åŒè¯„åˆ†ç­‰çº§çš„é¢„æµ‹è¡¨ç°**
| è¯„åˆ†èŒƒå›´ | RMSE | æ ·æœ¬æ•°é‡ | æ•°æ®å æ¯” | é¢„æµ‹éš¾åº¦ |
|----------|------|----------|----------|----------|
| â­ 0.5-1.0 | 0.721 | 1,234 | 1.2% | ğŸŸ¢ è¾ƒæ˜“ |
| â­â­ 1.5-2.0 | 0.756 | 3,456 | 3.5% | ğŸŸ¢ è¾ƒæ˜“ |
| â­â­â­ 2.5-3.0 | 0.834 | 12,345 | 12.3% | ğŸŸ¡ ä¸­ç­‰ |
| â­â­â­â­ 3.5-4.0 | 0.867 | 34,567 | 34.6% | ğŸŸ¡ ä¸­ç­‰ |
| â­â­â­â­â­ 4.5-5.0 | 0.892 | 48,398 | 48.4% | ğŸ”´ è¾ƒéš¾ |

**ä¸åŒç”¨æˆ·ç¾¤ä½“çš„é¢„æµ‹æ•ˆæœ**
| ç”¨æˆ·ç±»å‹ | è¯„åˆ†æ•°èŒƒå›´ | RMSE | ç”¨æˆ·æ•°é‡ | ç‰¹ç‚¹åˆ†æ |
|----------|------------|------|----------|----------|
| æ–°ç”¨æˆ· | 1-10 | 0.923 | 45,123 | æ•°æ®ç¨€å°‘ï¼Œé¢„æµ‹å›°éš¾ |
| æ™®é€šç”¨æˆ· | 11-50 | 0.854 | 23,456 | æ•°æ®é€‚ä¸­ï¼Œæ•ˆæœè‰¯å¥½ |
| æ´»è·ƒç”¨æˆ· | 51-200 | 0.798 | 3,456 | æ•°æ®ä¸°å¯Œï¼Œé¢„æµ‹å‡†ç¡® |
| è¶…çº§ç”¨æˆ· | 200+ | 0.743 | 234 | æ•°æ®å……è¶³ï¼Œæ•ˆæœæœ€ä½³ |

### æ€§èƒ½æå‡æŒ‡å—

#### æ¨¡å‹ç®—æ³•ä¼˜åŒ–
1. **è¶…å‚æ•°è°ƒä¼˜**: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–æ‰¾åˆ°æœ€ä½³å‚æ•°ç»„åˆ
2. **ç‰¹å¾é€‰æ‹©**: ç§»é™¤ä½é‡è¦æ€§ç‰¹å¾ï¼Œå‡å°‘å™ªå£°å’Œè¿‡æ‹Ÿåˆé£é™©
3. **æ¨¡å‹é›†æˆ**: ç»“åˆå¤šç§ç®—æ³•çš„é¢„æµ‹ç»“æœï¼Œæå‡æ•´ä½“æ€§èƒ½
4. **æ­£åˆ™åŒ–æŠ€æœ¯**: å¢åŠ L1/L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢æ¨¡å‹è¿‡åº¦å¤æ‚åŒ–

#### ç‰¹å¾å·¥ç¨‹æå‡
1. **åºåˆ—ç‰¹å¾**: å¢åŠ ç”¨æˆ·è¡Œä¸ºæ—¶é—´åºåˆ—ç‰¹å¾ï¼Œæ•æ‰åŠ¨æ€åå¥½
2. **æ—¶é—´æ¨¡å¼**: è€ƒè™‘è¯„åˆ†æ—¶é—´çš„å‘¨æœŸæ€§å’Œå­£èŠ‚æ€§æ¨¡å¼
3. **äº¤äº’ç‰¹å¾**: åˆ›å»ºæ›´å¤šç”¨æˆ·-ç‰©å“-ä¸Šä¸‹æ–‡çš„äº¤äº’ç‰¹å¾
4. **å¤–éƒ¨æ•°æ®**: é›†æˆç”µå½±ç¥¨æˆ¿ã€æ¼”å‘˜ä¿¡æ¯ã€ç¤¾äº¤åª’ä½“æ•°æ®ç­‰

#### æ•°æ®å±‚é¢ä¼˜åŒ–
1. **æ•°æ®å¢å¼º**: ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯æ‰©å……è®­ç»ƒé›†
2. **é‡‡æ ·ç­–ç•¥**: å¹³è¡¡ä¸åŒè¯„åˆ†ç­‰çº§çš„æ ·æœ¬åˆ†å¸ƒ
3. **å™ªå£°å¤„ç†**: è¯†åˆ«å’Œå¤„ç†æ ‡æ³¨å™ªå£°
4. **å†·å¯åŠ¨**: æ”¹è¿›æ–°ç”¨æˆ·å’Œæ–°ç‰©å“çš„å¤„ç†ç­–ç•¥

## å¯è§†åŒ–åˆ†æ

### å›¾è¡¨å±•ç¤º

ç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆåˆ†æå›¾è¡¨ï¼š

#### 1. é¢„æµ‹æ•ˆæœå¯è§†åŒ–

**çœŸå®å€¼vsé¢„æµ‹å€¼å¯¹æ¯”å›¾**
```python
from visualization.basic_plots import plot_boxplot_true_vs_pred

# ç”Ÿæˆé¢„æµ‹æ•ˆæœç®±çº¿å›¾
fig = plot_boxplot_true_vs_pred(predictions_df)
print("é¢„æµ‹æ•ˆæœå¯¹æ¯”å›¾å·²ç”Ÿæˆ")
```
**å›¾è¡¨ä»·å€¼**:
- ä¸€çœ¼çœ‹å‡ºé¢„æµ‹çš„å‡†ç¡®ç¨‹åº¦
- å¿«é€Ÿè¯†åˆ«ç³»ç»Ÿæ€§é¢„æµ‹åå·®
- è¯„ä¼°ä¸åŒè¯„åˆ†ç­‰çº§çš„é¢„æµ‹è´¨é‡

**é¢„æµ‹è¯„åˆ†åˆ†å¸ƒåˆ†æ**
```python
from visualization.basic_plots import plot_predicted_rating_hist

# ç”Ÿæˆé¢„æµ‹åˆ†å¸ƒç›´æ–¹å›¾
fig = plot_predicted_rating_hist(predictions_df)
print("è¯„åˆ†åˆ†å¸ƒå›¾å·²å®Œæˆ")
```
**æ´å¯Ÿå‘ç°**:
- åˆ†æé¢„æµ‹ç»“æœçš„æ•´ä½“åˆ†å¸ƒç‰¹å¾
- æ£€æŸ¥é¢„æµ‹è¯„åˆ†èŒƒå›´çš„åˆç†æ€§
- è¯†åˆ«æ¨¡å‹çš„è¯„åˆ†åå¥½æ¨¡å¼

#### 2. è¯¯å·®æ·±åº¦åˆ†æ

**é¢„æµ‹è¯¯å·®åˆ†å¸ƒå›¾**
```python
from visualization.error_analysis import plot_error_distribution

# æ·±åº¦åˆ†æé¢„æµ‹è¯¯å·®
fig = plot_error_distribution(predictions_df, show_stats=True)
print("è¯¯å·®åˆ†å¸ƒåˆ†æå·²å®Œæˆ")
```
**åˆ†æä»·å€¼**:
- æ­ç¤ºé¢„æµ‹è¯¯å·®çš„ç»Ÿè®¡è§„å¾‹
- å¿«é€Ÿå‘ç°å¼‚å¸¸è¯¯å·®æ¨¡å¼
- è¯„ä¼°æ¨¡å‹é¢„æµ‹çš„ç¨³å®šæ€§

**æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾**
```python
from visualization.error_analysis import plot_confusion_heatmap

# ç”Ÿæˆè¯¦ç»†æ··æ·†çŸ©é˜µ
fig = plot_confusion_heatmap(predictions_df, normalize='true')
print("æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾å·²ç”Ÿæˆ")
```
**æ·±åº¦æ´å¯Ÿ**:
- è¯¦ç»†åˆ†æå„ç±»åˆ«çš„åˆ†ç±»å‡†ç¡®æ€§
- è¯†åˆ«å®¹æ˜“æ··æ·†çš„è¯„åˆ†ç­‰çº§ç»„åˆ
- å‘ç°æ¨¡å‹çš„ç³»ç»Ÿæ€§é¢„æµ‹åå·®

**ç”¨æˆ·ç¾¤ä½“è¯¯å·®åˆ†æ**
```python
from visualization.error_analysis import plot_user_error_distribution

# åˆ†æä¸åŒç”¨æˆ·çš„é¢„æµ‹è¡¨ç°
fig = plot_user_error_distribution(predictions_df)
print("ç”¨æˆ·è¯¯å·®åˆ†æå·²å®Œæˆ")
```
**ä¸ªæ€§åŒ–æ´å¯Ÿ**:
- åˆ†æä¸åŒç”¨æˆ·ç¾¤ä½“çš„é¢„æµ‹å‡†ç¡®æ€§
- è¯†åˆ«éš¾ä»¥é¢„æµ‹çš„ç‰¹æ®Šç”¨æˆ·ç¾¤ä½“
- ä¸ºä¸ªæ€§åŒ–æ¨èç­–ç•¥æä¾›ä¼˜åŒ–æ–¹å‘

#### 3. ç‰¹å¾æ´å¯Ÿåˆ†æ

**ç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œ**
```python
from visualization.feature_plots import plot_top20_feature_importance

# å‘ç°æœ€é‡è¦çš„é¢„æµ‹å› å­
fig = plot_top20_feature_importance(models, X_train, feature_names)
print("ç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œå·²ç”Ÿæˆ")
```
**ä¸šåŠ¡ä»·å€¼**:
- è¯†åˆ«å½±å“ç”¨æˆ·è¯„åˆ†çš„å…³é”®å› ç´ 
- ä¸ºç‰¹å¾å·¥ç¨‹ä¼˜åŒ–æä¾›æ˜ç¡®æ–¹å‘
- å¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯ä¿¡åº¦

**ğŸŒ¡ï¸ ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾**
```python
from visualization.feature_plots import plot_feature_correlation

# ğŸ”— æ­ç¤ºç‰¹å¾é—´çš„éšè—å…³è”
fig = plot_feature_correlation(df, feature_columns, target='rating')
print("ğŸŒ¡ï¸ ç‰¹å¾ç›¸å…³æ€§åˆ†æå·²å®Œæˆ")
```
âœ¨ **ä¼˜åŒ–æŒ‡å¯¼**:
- ğŸ” æ·±åº¦åˆ†æç‰¹å¾é—´çš„ç›¸äº’å…³ç³»
- ğŸš¨ è¯†åˆ«å†—ä½™ç‰¹å¾ï¼Œé¿å…ä¿¡æ¯é‡å¤
- ğŸ’¡ å‘ç°æœ‰ä»·å€¼çš„ç‰¹å¾ç»„åˆæœºä¼š

**ğŸ“Š ç‰¹å¾åˆ†å¸ƒç‰¹æ€§å›¾**
```python
from visualization.feature_plots import plot_feature_distributions

# ğŸ“ˆ åˆ†æç‰¹å¾çš„ç»Ÿè®¡ç‰¹æ€§
fig = plot_feature_distributions(df, feature_columns)
print("ğŸ“Š ç‰¹å¾åˆ†å¸ƒåˆ†æå·²å®Œæˆ")
```
âœ¨ **æ•°æ®æ´å¯Ÿ**:
- ğŸ“ˆ å…¨é¢äº†è§£ç‰¹å¾çš„åˆ†å¸ƒç‰¹å¾
- ğŸš¨ å¿«é€Ÿè¯†åˆ«å¼‚å¸¸å€¼å’Œæ•°æ®åæ–œ
- ğŸ”§ ä¸ºç‰¹å¾é¢„å¤„ç†æä¾›ç§‘å­¦ä¾æ®

#### 4. â° æ—¶é—´åºåˆ—æ´å¯Ÿ

**ğŸ“ˆ è¯„åˆ†è¶‹åŠ¿å˜åŒ–åˆ†æ**
```python
from visualization.error_analysis import plot_error_by_year

# â° åˆ†ææ—¶é—´ç»´åº¦çš„é¢„æµ‹è¡¨ç°
fig = plot_error_by_year(predictions_df, df, val_indices)
print("ğŸ“ˆ æ—¶é—´è¶‹åŠ¿åˆ†æå·²å®Œæˆ")
```
âœ¨ **æ—¶é—´æ´å¯Ÿ**:
- ğŸ“Š æ­ç¤ºç”¨æˆ·è¯„åˆ†éšæ—¶é—´çš„æ¼”å˜è¶‹åŠ¿
- ğŸ”„ è¯†åˆ«å­£èŠ‚æ€§å’Œå‘¨æœŸæ€§è¯„åˆ†æ¨¡å¼
- âš–ï¸ è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ—¶æœŸçš„ç¨³å®šæ€§

**ğŸ”¥ çƒ­åº¦å…³è”æ€§åˆ†æ**
```python
from visualization.error_analysis import plot_error_vs_popularity

# ğŸ¬ åˆ†æç”µå½±çƒ­åº¦å¯¹é¢„æµ‹çš„å½±å“
fig = plot_error_vs_popularity(predictions_df, movie_stats)
print("ğŸ”¥ çƒ­åº¦å…³è”åˆ†æå·²å®Œæˆ")
```
âœ¨ **å•†ä¸šæ´å¯Ÿ**:
- ğŸ“Š æ·±åº¦åˆ†æé¢„æµ‹è¯¯å·®ä¸ç”µå½±çƒ­åº¦çš„å…³ç³»
- ğŸ¯ è¯†åˆ«å†·é—¨ç”µå½±çš„é¢„æµ‹æŒ‘æˆ˜å’Œæœºä¼š
- ğŸ’¡ ä¸ºé•¿å°¾æ¨èç­–ç•¥æä¾›ä¼˜åŒ–å»ºè®®

### ğŸ¨ ä¸ªæ€§åŒ–å›¾è¡¨å®šåˆ¶

#### ğŸ¨ ç¾åŒ–æ ·å¼é…ç½®
è®©æ‚¨çš„å›¾è¡¨æ›´åŠ ä¸“ä¸šå’Œç¾è§‚ï¼š
```python
# ğŸ¨ è®¾ç½®ä¸“ä¸šçº§å›¾è¡¨æ ·å¼
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.size'] = 12           # ğŸ“ è®¾ç½®å­—ä½“å¤§å°
plt.rcParams['figure.figsize'] = (10, 8)  # ğŸ“ è®¾ç½®å›¾è¡¨å°ºå¯¸
sns.set_style("whitegrid")                # ğŸ¯ é€‰æ‹©æ¸…çˆ½ç½‘æ ¼é£æ ¼
sns.set_palette("husl")                   # ğŸŒˆ ä½¿ç”¨å’Œè°è‰²å½©æ–¹æ¡ˆ
print("ğŸ¨ å›¾è¡¨æ ·å¼å·²ä¼˜åŒ–")
```

#### ğŸŒˆ è‡ªå®šä¹‰é…è‰²æ–¹æ¡ˆ
```python
# ğŸ¨ æ‰“é€ ç‹¬ç‰¹çš„è§†è§‰é£æ ¼
custom_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
sns.set_palette(custom_colors)
print("ğŸŒˆ è‡ªå®šä¹‰é…è‰²æ–¹æ¡ˆå·²åº”ç”¨")
```

#### ğŸš€ äº¤äº’å¼å›¾è¡¨ä½“éªŒ
```python
import plotly.express as px
import plotly.graph_objects as go

# ğŸš€ åˆ›å»ºåŠ¨æ€äº¤äº’å¼å›¾è¡¨
fig = px.scatter(predictions_df, 
                x='true_rating', 
                y='pred_rating',
                color='error',                    # ğŸ¨ æŒ‰è¯¯å·®ç€è‰²
                hover_data=['userId', 'movieId'], # ğŸ“Š æ‚¬åœæ˜¾ç¤ºè¯¦æƒ…
                title='ğŸ¯ äº¤äº’å¼é¢„æµ‹æ•ˆæœåˆ†æ')
fig.show()
print("ğŸš€ äº¤äº’å¼å›¾è¡¨å·²å¯åŠ¨ï¼Œå¯åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹")
```

## â“ å¸¸è§é—®é¢˜è§£ç­”

### ğŸ”§ å®‰è£…ç›¸å…³é—®é¢˜

**Q: å®‰è£…LightGBMæ—¶é‡åˆ°ç¼–è¯‘é”™è¯¯æ€ä¹ˆåŠï¼Ÿ**

A: åˆ«æ‹…å¿ƒï¼è¿™æ˜¯å¾ˆå¸¸è§çš„é—®é¢˜ï¼Œè¯•è¯•è¿™äº›è§£å†³æ–¹æ¡ˆï¼š
```bash
# ğŸ¯ æ–¹æ¡ˆ1: ä½¿ç”¨condaå®‰è£…ï¼ˆæ¨èï¼‰
conda install -c conda-forge lightgbm
echo "âœ… LightGBMå®‰è£…å®Œæˆï¼"

# ğŸš€ æ–¹æ¡ˆ2: å®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install --prefer-binary lightgbm
echo "âœ… é¢„ç¼–è¯‘ç‰ˆæœ¬å®‰è£…æˆåŠŸï¼"

# ğŸ”§ æ–¹æ¡ˆ3: å…ˆå®‰è£…ç¼–è¯‘å·¥å…·
# Windowsç”¨æˆ·:
pip install cmake
# macOSç”¨æˆ·:
brew install cmake
# Ubuntuç”¨æˆ·:
sudo apt-get install cmake
echo "ğŸ› ï¸ ç¼–è¯‘ç¯å¢ƒå·²å‡†å¤‡å°±ç»ªï¼"
```

**Q: è¿è¡Œæ—¶æç¤ºæ‰¾ä¸åˆ°æ¨¡å—è·¯å¾„ï¼Ÿ**

A: ç®€å•è®¾ç½®ä¸€ä¸‹é¡¹ç›®è·¯å¾„å³å¯ï¼š
```python
# ğŸ› ï¸ è‡ªåŠ¨æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
print("âœ… é¡¹ç›®è·¯å¾„é…ç½®å®Œæˆ")
```

### ğŸ“Š æ•°æ®ç›¸å…³é—®é¢˜

**Q: æç¤ºæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Ÿ**

A: è®©æˆ‘ä»¬ä¸€èµ·æ£€æŸ¥æ•°æ®è·¯å¾„é…ç½®ï¼š
```python
# ğŸ” æ™ºèƒ½æ£€æŸ¥æ•°æ®æ–‡ä»¶çŠ¶æ€
import os
from config import config

print(f"ğŸ“ æ•°æ®ç›®å½•: {config.base_dir}")
print(f"â­ è¯„åˆ†æ–‡ä»¶å­˜åœ¨: {os.path.exists(config.ratings_file)}")
print(f"ğŸ¬ ç”µå½±æ–‡ä»¶å­˜åœ¨: {os.path.exists(config.movies_file)}")
print("ğŸ¯ æ•°æ®æ–‡ä»¶æ£€æŸ¥å®Œæˆï¼")
```

**Q: è¿è¡Œæ—¶æç¤ºå†…å­˜ä¸è¶³ï¼Ÿ**

A: åˆ«æ‹…å¿ƒï¼æˆ‘ä»¬æ¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼š
```python
# ğŸ’¡ æ™ºèƒ½å†…å­˜ä¼˜åŒ–ç­–ç•¥

# ğŸ¯ å‡å°‘ç‰¹å¾ç»´åº¦
config.latent_dim = 10      # é™ä½æ½œåœ¨å› å­ç»´åº¦
config.tfidf_dim = 50       # å‡å°‘TF-IDFç‰¹å¾æ•°
print("ğŸ“‰ ç‰¹å¾ç»´åº¦å·²ä¼˜åŒ–")

# ğŸ“Š ä½¿ç”¨æ•°æ®é‡‡æ ·
ratings_sample = ratings.sample(frac=0.5, random_state=42)
print("ğŸ² æ•°æ®é‡‡æ ·å®Œæˆï¼Œå†…å­˜ä½¿ç”¨å‡åŠ")

# âš¡ åˆ†æ‰¹å¤„ç†å¤§æ•°æ®
from sklearn.model_selection import train_test_split
X_train, X_temp = train_test_split(X, test_size=0.5, random_state=42)
print("ğŸ“¦ æ•°æ®å·²åˆ†æ‰¹ï¼Œå†…å­˜å‹åŠ›å¤§å¹…å‡è½»")
```

### ğŸ¤– æ¨¡å‹è®­ç»ƒé—®é¢˜

**Q: æ¨¡å‹è®­ç»ƒæ—¶é—´å¤ªé•¿äº†ï¼Ÿ**

A: è®©æˆ‘ä»¬æ¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼š
```python
# âš¡ è®­ç»ƒåŠ é€Ÿä¼˜åŒ–æ–¹æ¡ˆ

# ğŸŒ³ å‡å°‘æ ‘çš„æ•°é‡ï¼ˆå¿«é€Ÿè®­ç»ƒï¼‰
config.n_estimators = 100
print("ğŸŒ³ æ ‘æ•°é‡å·²ä¼˜åŒ–ï¼Œè®­ç»ƒæ›´å¿«")

# ğŸ“ˆ æé«˜å­¦ä¹ ç‡ï¼ˆåŠ å¿«æ”¶æ•›ï¼‰
config.learning_rate = 0.1
print("ğŸ“ˆ å­¦ä¹ ç‡å·²æå‡")

# ğŸƒ å‡å°‘å¶å­èŠ‚ç‚¹æ•°ï¼ˆç®€åŒ–æ¨¡å‹ï¼‰
config.num_leaves = 31
print("ğŸƒ æ¨¡å‹å¤æ‚åº¦å·²ä¼˜åŒ–")

# ğŸ›‘ å¯ç”¨æ—©åœæœºåˆ¶ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
early_stopping_rounds = 50
print("ğŸ›‘ æ—©åœæœºåˆ¶å·²å¯ç”¨ï¼Œè®­ç»ƒæ›´æ™ºèƒ½")
```

**Q: é¢„æµ‹æ•ˆæœä¸å¤Ÿç†æƒ³ï¼Ÿ**

A: è¯•è¯•è¿™äº›æ¨¡å‹ä¼˜åŒ–ç­–ç•¥ï¼š
```python
# ğŸ¯ æ¨¡å‹æ•ˆæœæå‡æŒ‡å—

print("ğŸ”§ ä¼˜åŒ–ç­–ç•¥æ¸…å•:")
print("1. ğŸ—ï¸  å¢å¼ºç‰¹å¾å·¥ç¨‹ - åˆ›é€ æ›´æœ‰ä»·å€¼çš„ç‰¹å¾")
print("2. âš™ï¸  ç²¾è°ƒæ¨¡å‹å‚æ•° - æ‰¾åˆ°æœ€ä½³é…ç½®")
print("3. ğŸ”„ ä½¿ç”¨äº¤å‰éªŒè¯ - ç¡®ä¿æ¨¡å‹ç¨³å®šæ€§")
print("4. ğŸ” æ£€æŸ¥æ•°æ®è´¨é‡ - æ¸…ç†å¼‚å¸¸æ•°æ®")
print("5. ğŸ¯ è¿›è¡Œç‰¹å¾é€‰æ‹© - ä¿ç•™æœ€é‡è¦ç‰¹å¾")
print("ğŸ’¡ å»ºè®®é€ä¸€å°è¯•ï¼Œæ•ˆæœä¼šé€æ­¥æå‡ï¼")
```

### ğŸ“ˆ å¯è§†åŒ–ç›¸å…³é—®é¢˜

**Q: å›¾è¡¨ä¸­æ–‡å­—æ˜¾ç¤ºä¸ºä¹±ç ï¼Ÿ**

A: ç®€å•é…ç½®ä¸€ä¸‹ä¸­æ–‡å­—ä½“å°±å¥½äº†ï¼š
```python
# ğŸ¨ è§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
import matplotlib.pyplot as plt

# ğŸ”¤ è®¾ç½®æ”¯æŒä¸­æ–‡çš„å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
print("ğŸ¨ ä¸­æ–‡å­—ä½“é…ç½®å®Œæˆï¼Œå›¾è¡¨æ˜¾ç¤ºæ­£å¸¸ï¼")
```

**Q: å›¾è¡¨ä¿å­˜æ—¶å‡ºç°é”™è¯¯ï¼Ÿ**

A: è®©æˆ‘ä»¬æ£€æŸ¥å¹¶ä¿®å¤ä¿å­˜é—®é¢˜ï¼š
```python
# ğŸ”§ æ™ºèƒ½è¯Šæ–­å›¾è¡¨ä¿å­˜é—®é¢˜
import os

# ğŸ“ ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(config.save_dir, exist_ok=True)
print(f"ğŸ“ è¾“å‡ºç›®å½•å·²åˆ›å»º: {config.save_dir}")

# âœ… æµ‹è¯•å†™å…¥æƒé™
test_file = os.path.join(config.save_dir, 'test.txt')
try:
    with open(test_file, 'w') as f:
        f.write('æƒé™æµ‹è¯•')
    os.remove(test_file)
    print("âœ… å†™å…¥æƒé™æ­£å¸¸ï¼Œå¯ä»¥ä¿å­˜å›¾è¡¨")
except Exception as e:
    print(f"âŒ å†™å…¥æƒé™é”™è¯¯: {e}")
    print("ğŸ’¡ å»ºè®®æ£€æŸ¥ç›®å½•æƒé™æˆ–æ›´æ¢ä¿å­˜è·¯å¾„")
```

### ğŸ§ª å®éªŒç®¡ç†é—®é¢˜

**Q: å®éªŒç»“æœæ¯æ¬¡éƒ½ä¸ä¸€æ ·ï¼Œæ— æ³•å¤ç°ï¼Ÿ**

A: è®¾ç½®éšæœºç§å­ï¼Œè®©å®éªŒç»“æœå¯é‡ç°ï¼š
```python
# ğŸ¯ ç¡®ä¿å®éªŒç»“æœå¯é‡ç°
import random
import numpy as np
from sklearn.utils import check_random_state

# ğŸ”’ è®¾ç½®å…¨å±€éšæœºç§å­
random.seed(42)
np.random.seed(42)
config.seed = 42
print("ğŸ”’ éšæœºç§å­å·²å›ºå®šä¸º42")

# ğŸ¤– åœ¨æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨ç›¸åŒç§å­
models = train_models(X_train, y_train, seed=42)
print("âœ… å®éªŒç»“æœç°åœ¨å¯ä»¥å®Œç¾å¤ç°äº†ï¼")
```

**Q: é‡è¦çš„å®éªŒè®°å½•ä¸è§äº†ï¼Ÿ**

A: è®©æˆ‘ä»¬æ£€æŸ¥å¹¶å¤‡ä»½å®éªŒæ•°æ®ï¼š
```python
# ğŸ” æ™ºèƒ½å®éªŒç®¡ç†
import os
import shutil

# ğŸ“Š æ£€æŸ¥ç°æœ‰å®éªŒ
experiments = os.listdir('experiments')
print(f"ğŸ“Š å‘ç° {len(experiments)} ä¸ªå®éªŒè®°å½•")
for exp in experiments[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
    print(f"  ğŸ“ {exp}")

# ğŸ’¾ å¤‡ä»½é‡è¦å®éªŒï¼ˆæ¨èå®šæœŸæ‰§è¡Œï¼‰
try:
    shutil.copytree('experiments/important_exp', 'backup/important_exp')
    print("ğŸ’¾ é‡è¦å®éªŒå·²å¤‡ä»½åˆ°backupç›®å½•")
except FileNotFoundError:
    print("ğŸ’¡ å»ºè®®ä¸ºé‡è¦å®éªŒåˆ›å»ºå¤‡ä»½")
except FileExistsError:
    print("âœ… å¤‡ä»½å·²å­˜åœ¨ï¼Œå®éªŒæ•°æ®å®‰å…¨")
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### ğŸ“‹ è´¡çŒ®æ–¹å¼

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

- ğŸ› **BugæŠ¥å‘Š**: å‘ç°å¹¶æŠ¥å‘Šç³»ç»Ÿä¸­çš„é—®é¢˜
- ğŸ’¡ **åŠŸèƒ½å»ºè®®**: æå‡ºæ–°åŠŸèƒ½æˆ–æ”¹è¿›å»ºè®®
- ğŸ“ **æ–‡æ¡£æ”¹è¿›**: å®Œå–„æ–‡æ¡£å’Œæ•™ç¨‹
- ğŸ”§ **ä»£ç è´¡çŒ®**: æäº¤ä»£ç ä¿®å¤æˆ–æ–°åŠŸèƒ½
- ğŸ§ª **æµ‹è¯•ç”¨ä¾‹**: æ·»åŠ æµ‹è¯•ç”¨ä¾‹æé«˜ä»£ç è´¨é‡
- ğŸ“Š **æ•°æ®é›†**: è´¡çŒ®æ–°çš„æ•°æ®é›†æˆ–åŸºå‡†æµ‹è¯•

### ğŸ”„ å¼€å‘æµç¨‹

#### 1. ç¯å¢ƒå‡†å¤‡
```bash
# Forké¡¹ç›®åˆ°ä½ çš„GitHubè´¦æˆ·
# å…‹éš†ä½ çš„Fork
git clone https://github.com/your-username/movie-recommendation-system.git
cd movie-recommendation-system

# æ·»åŠ ä¸Šæ¸¸ä»“åº“
git remote add upstream https://github.com/original-repo/movie-recommendation-system.git

# åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/your-feature-name
```

#### 2. å¼€å‘è§„èŒƒ

**ä»£ç é£æ ¼**
- éµå¾ªPEP 8 Pythonä»£ç è§„èŒƒ
- ä½¿ç”¨æœ‰æ„ä¹‰çš„å˜é‡å’Œå‡½æ•°å
- æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- ä¿æŒä»£ç ç®€æ´å’Œå¯è¯»æ€§

**æäº¤è§„èŒƒ**
```bash
# æäº¤ä¿¡æ¯æ ¼å¼
git commit -m "type(scope): description"

# ç¤ºä¾‹
git commit -m "feat(models): add ensemble learning support"
git commit -m "fix(data): resolve memory leak in data loading"
git commit -m "docs(readme): update installation guide"
```

**ç±»å‹è¯´æ˜**
- `feat`: æ–°åŠŸèƒ½
- `fix`: Bugä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼è°ƒæ•´
- `refactor`: ä»£ç é‡æ„
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»ºæˆ–è¾…åŠ©å·¥å…·å˜åŠ¨

#### 3. æµ‹è¯•è¦æ±‚

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_models.py -v

# æ£€æŸ¥ä»£ç è¦†ç›–ç‡
python -m pytest --cov=. tests/

# ä»£ç é£æ ¼æ£€æŸ¥
flake8 .
black --check .
```

#### 4. æäº¤Pull Request

1. **ç¡®ä¿ä»£ç è´¨é‡**
   - æ‰€æœ‰æµ‹è¯•é€šè¿‡
   - ä»£ç é£æ ¼ç¬¦åˆè§„èŒƒ
   - æ·»åŠ å¿…è¦çš„æ–‡æ¡£

2. **åˆ›å»ºPull Request**
   - æä¾›æ¸…æ™°çš„æ ‡é¢˜å’Œæè¿°
   - è¯´æ˜å˜æ›´çš„åŸå› å’Œå½±å“
   - å…³è”ç›¸å…³çš„Issue

3. **ä»£ç å®¡æŸ¥**
   - å“åº”å®¡æŸ¥æ„è§
   - åŠæ—¶ä¿®å¤é—®é¢˜
   - ä¿æŒæ²Ÿé€š

### ğŸ“ å¼€å‘æŒ‡å—

#### æ·»åŠ æ–°ç‰¹å¾

```python
# 1. åœ¨data/data_loader.pyä¸­æ·»åŠ ç‰¹å¾æå–å‡½æ•°
def create_new_features(data: pd.DataFrame) -> pd.DataFrame:
    """
    åˆ›å»ºæ–°çš„ç‰¹å¾
    
    Args:
        data: è¾“å…¥æ•°æ®
    
    Returns:
        åŒ…å«æ–°ç‰¹å¾çš„DataFrame
    """
    # å®ç°ç‰¹å¾æå–é€»è¾‘
    pass

# 2. åœ¨main.pyä¸­é›†æˆæ–°ç‰¹å¾
new_features = create_new_features(df)
df = pd.concat([df, new_features], axis=1)

# 3. æ›´æ–°ç‰¹å¾åˆ—è¡¨
feature_columns.extend(new_features.columns.tolist())
```

#### æ·»åŠ æ–°æ¨¡å‹

```python
# 1. åœ¨models/ç›®å½•ä¸‹åˆ›å»ºæ–°æ¨¡å‹æ–‡ä»¶
# models/new_model.py
class NewModel:
    def __init__(self, **kwargs):
        self.params = kwargs
    
    def fit(self, X, y):
        # å®ç°è®­ç»ƒé€»è¾‘
        pass
    
    def predict(self, X):
        # å®ç°é¢„æµ‹é€»è¾‘
        pass

# 2. åœ¨models/train_eval.pyä¸­é›†æˆæ–°æ¨¡å‹
from .new_model import NewModel

def train_new_model(X_train, y_train, **kwargs):
    model = NewModel(**kwargs)
    model.fit(X_train, y_train)
    return model
```

#### æ·»åŠ æ–°å¯è§†åŒ–

```python
# 1. åœ¨visualization/ç›®å½•ä¸‹æ·»åŠ æ–°å›¾è¡¨å‡½æ•°
def plot_new_analysis(data, save_path=None):
    """
    åˆ›å»ºæ–°çš„åˆ†æå›¾è¡¨
    
    Args:
        data: åˆ†ææ•°æ®
        save_path: ä¿å­˜è·¯å¾„
    
    Returns:
        matplotlibå›¾è¡¨å¯¹è±¡
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    # å®ç°ç»˜å›¾é€»è¾‘
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    
    return fig

# 2. åœ¨main.pyä¸­è°ƒç”¨æ–°å›¾è¡¨
from visualization.new_plots import plot_new_analysis
plot_new_analysis(analysis_data, 'output/new_analysis.png')
```

### æµ‹è¯•æŒ‡å—

#### ç¼–å†™å•å…ƒæµ‹è¯•

```python
# tests/test_new_feature.py
import unittest
import pandas as pd
from data.data_loader import create_new_features

class TestNewFeatures(unittest.TestCase):
    def setUp(self):
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        self.test_data = pd.DataFrame({
            'userId': [1, 2, 3],
            'movieId': [1, 2, 3],
            'rating': [4.0, 3.5, 5.0]
        })
    
    def test_create_new_features(self):
        # æµ‹è¯•æ–°ç‰¹å¾åˆ›å»º
        features = create_new_features(self.test_data)
        self.assertIsInstance(features, pd.DataFrame)
        self.assertGreater(len(features.columns), 0)
    
    def test_feature_values(self):
        # æµ‹è¯•ç‰¹å¾å€¼çš„åˆç†æ€§
        features = create_new_features(self.test_data)
        self.assertFalse(features.isnull().any().any())

if __name__ == '__main__':
    unittest.main()
```

#### é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
import unittest
from main import main

class TestIntegration(unittest.TestCase):
    def test_full_pipeline(self):
        # æµ‹è¯•å®Œæ•´æµç¨‹
        try:
            main()
            self.assertTrue(True)
        except Exception as e:
            self.fail(f"Pipeline failed with error: {e}")
```

## æ›´æ–°æ—¥å¿—

### ç‰ˆæœ¬ 2.0.0 (2024-12-01)

#### æ–°åŠŸèƒ½
- æ·»åŠ åºæ•°åˆ†ç±»æ”¯æŒï¼Œæå‡è¯„åˆ†é¢„æµ‹å‡†ç¡®æ€§
- é‡æ„ç‰¹å¾å·¥ç¨‹æ¨¡å—ï¼Œæ”¯æŒæ›´å¤šç‰¹å¾ç±»å‹
- æ–°å¢20+ç§å¯è§†åŒ–å›¾è¡¨å’Œåˆ†æå·¥å…·
- å®Œæ•´çš„å®éªŒç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
- å…¨é¢çš„APIæ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

#### æ€§èƒ½ä¼˜åŒ–
- ä¼˜åŒ–LightGBMè®­ç»ƒå‚æ•°ï¼Œæå‡è®­ç»ƒé€Ÿåº¦30%
- æ”¹è¿›å†…å­˜ä½¿ç”¨ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®é›†
- å¹¶è¡ŒåŒ–ç‰¹å¾å·¥ç¨‹ï¼Œå‡å°‘å¤„ç†æ—¶é—´
- ä¼˜åŒ–é¢„æµ‹æµç¨‹ï¼Œæå‡æ¨ç†é€Ÿåº¦

#### Bugä¿®å¤
- ä¿®å¤LightGBM APIå…¼å®¹æ€§é—®é¢˜
- ä¿®å¤å¯è§†åŒ–å›¾è¡¨ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
- ä¿®å¤å¤§æ•°æ®é›†å†…å­˜æº¢å‡ºé—®é¢˜
- ä¿®å¤ç‰¹å¾é‡è¦æ€§è®¡ç®—é”™è¯¯

#### æ–‡æ¡£æ”¹è¿›
- å®Œå–„READMEæ–‡æ¡£ï¼Œæ·»åŠ è¯¦ç»†ä½¿ç”¨æŒ‡å—
- æ–°å¢å¿«é€Ÿå¼€å§‹æ•™ç¨‹
- æ·»åŠ APIæ–‡æ¡£å’Œä»£ç ç¤ºä¾‹
- å®Œå–„å®‰è£…å’Œé…ç½®è¯´æ˜

### ç‰ˆæœ¬ 1.5.0 (2024-11-15)

#### æ–°åŠŸèƒ½
- æ·»åŠ æ•°æ®é¢„å¤„ç†å’Œå¼‚å¸¸å€¼æ£€æµ‹
- æ–°å¢ç”¨æˆ·å’Œç”µå½±ç”»åƒç‰¹å¾
- æ”¹è¿›å¯è§†åŒ–å›¾è¡¨æ ·å¼å’Œäº¤äº’æ€§
- æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ç³»ç»Ÿ

#### æ€§èƒ½ä¼˜åŒ–
- ä¼˜åŒ–SVDçŸ©é˜µåˆ†è§£ç®—æ³•
- æ”¹è¿›æ•°æ®åŠ è½½å’Œç¼“å­˜æœºåˆ¶
- ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹æµç¨‹

### ç‰ˆæœ¬ 1.0.0 (2024-10-01)

#### åˆå§‹ç‰ˆæœ¬
- åŸºç¡€LightGBMæ¨¡å‹å®ç°
- ååŒè¿‡æ»¤å’Œå†…å®¹ç‰¹å¾
- åŸºç¡€å¯è§†åŒ–åŠŸèƒ½
- é¡¹ç›®åŸºç¡€æ¶æ„

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

### è®¸å¯è¯æ‘˜è¦

```
MIT License

Copyright (c) 2024 Movie Recommendation System

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```